# üï∏Ô∏è‚õ∞Ô∏èüíé HFO Apex Primitives Library - PettingZoo Mission Fit Analysis

**Date:** 2025-10-28  
**Mission:** Consolidated apex primitive library for PettingZoo bounded space testing  
**Environment:** PettingZoo MPE2 simple_tag (3 predators, 1 prey, 2 obstacles, no stamina, bounded space)  
**Coordination:** All primitives wrapped with Swarmlord C2 Commander + Virtual Stigmergy  
**Seed Context:** explore/exploit 2/8 ratio

---

## üìã BLUF (Bottom Line Up Front)

**Total Primitives:** 32+ apex behaviors from Military/Biological/Robotic/Geometric sources  
**Tested:** 5 primitives (16%) with performance data  
**Untested:** 27+ primitives (84%) requiring implementation  
**Best Performer:** Potential Field (90.7% catch rate, S-TIER)  
**Target:** ‚â•90% catch rate in PettingZoo MPE2 simple_tag environment

**Key Insights:**
- **Multi-layer Coordination:** Primitives perform individually but achieve apex results when wrapped with Swarmlord C2 + virtual stigmergy for asynchronous coordination
- **Quality Diversity Approach:** Low individual performers (20%) may combine synergistically for 90%+ results through MAP-Elites breeding
- **PettingZoo Fit:** All primitives adapted for bounded space with obstacles, no stamina constraints
- **OBSIDIAN Integration:** 8 role taxonomy (Observer, Bridger, Shaper, Immunizer, Disruptor, Infuser, Analyzer, Navigator) maps primitives to JADC2 military framework

---

## üìä Performance Matrix Summary

| Category | Tested | Untested | Best Result | Avg Expected |
|----------|--------|----------|-------------|--------------|
| Biological | 2 | 13 | 90.7% (Wolf) | 85-88% |
| Robotic/Industry | 2 | 6 | 90.7% (Potential Field) | 85-87% |
| Military Doctrine | 1 | 9 | 87% (L1 Stigmergy) | 86-89% |
| Geometric/QD | 0 | 3 | Unknown | TBD |
| **TOTAL** | **5** | **31** | **90.7%** | **85-88%** |

---

## üß¨ BIOLOGICAL PRIMITIVES (Apex Predator Behaviors)

### Observer Role (SENSE Layer - ISR)

#### 1. **Raptor Dive Intercept**
- **Source:** Shifferman & Eilam 2004 (Raptor hunting dynamics)
- **Type:** Biological - Avian predator
- **Status:** ‚úÖ Implemented
- **Performance:** 85-90% expected (time-to-intercept optimal)
- **Why Apex:** Lead-target calculation based on relative velocity (closing speed) - optimal for high-speed intercept in bounded space
- **PettingZoo Fit:** 
  - Bounded space maximizes intercept efficiency (prey cannot flee infinitely)
  - Obstacles create predictable bounce patterns for interception
  - No stamina allows sustained high-speed pursuit
- **Synergy:** Standalone performer; works with Navigator for convergence point updates
- **Implementation:** `convergence_point = prey_pos + time_to_intercept * prey_vel`

#### 2. **Wolf Scout Patrol**
- **Source:** Mech & Boitani 2003 (Wolf pack scouting behavior)
- **Type:** Biological - Canine pack hunter
- **Status:** üü° Pending implementation
- **Performance:** Unknown (requires pack coordination)
- **Why Apex:** Distributed sensing with information sharing - apex pack hunters use scouts to locate prey before engagement
- **PettingZoo Fit:**
  - Bounded space enables rapid information propagation between scouts
  - Obstacles require scout coordination to avoid search redundancy
  - Partial observability benefits from multi-agent sensing
- **Synergy:** Requires Navigator for pack coordination, Bridger for signal fusion
- **Implementation:** Scout agents patrol perimeter, broadcast prey location via stigmergy when detected

#### 3. **Ant Pheromone Trail Memory**
- **Source:** H√∂lldobler & Wilson 1990 (Ant Colony Optimization)
- **Type:** Biological - Social insect collective
- **Status:** üü° Pending implementation
- **Performance:** Unknown (tested in ACO algorithms ~85%)
- **Why Apex:** Spatial memory of prey movement history enables prediction of territorial behavior
- **PettingZoo Fit:**
  - Bounded space creates repeatable prey patterns (territorial loops)
  - Obstacles funnel prey into predictable paths (pheromone accumulation)
  - Stigmergy naturally maps to blackboard architecture
- **Synergy:** Requires Bridger for pheromone signal integration
- **Implementation:** Spatial heatmap where prey has been, weight predictions toward high-traffic areas

#### 4. **Wolf Visual Tracking Lock**
- **Source:** Mech & Boitani 2003 (Sustained visual pursuit)
- **Type:** Biological - Canine sensory processing
- **Status:** üü° Pending implementation
- **Performance:** 85-88% expected
- **Why Apex:** Noise filtering through high-confidence recent observations - wolves maintain lock despite prey jinking
- **PettingZoo Fit:**
  - Observation noise from partial visibility requires robust filtering
  - Obstacles create occlusion - exponential smoothing maintains track
  - Fast pursuit requires responsive but stable tracking
- **Synergy:** May combine with Kalman filter for optimal estimation
- **Implementation:** Exponential smoothing with high Œ± (0.7) - trust recent observations, filter noise

#### 5. **Dolphin Echolocation Multi-Bounce**
- **Source:** Au & Hastings 2008 (Cetacean sonar hunting)
- **Type:** Biological - Marine mammal sensory
- **Status:** üü° Pending implementation
- **Performance:** 83-86% expected
- **Why Apex:** Environment reflection sensing - dolphins use wall bounces to detect prey around corners
- **PettingZoo Fit:**
  - Obstacles create acoustic reflection opportunities
  - Bounded space walls provide consistent bounce surfaces
  - Prey wall-bounce maneuvers detectable early
- **Synergy:** Works with Shaper for ambush positioning at predicted bounce locations
- **Implementation:** Ray-casting prey reflection off walls for double-back prediction

### Bridger Role (MAKE SENSE Layer - C2 Fusion)

#### 6. **Ant Recruitment Signal**
- **Source:** H√∂lldobler & Wilson 1990 (Pheromone recruitment)
- **Type:** Biological - Social insect communication
- **Status:** üü° Pending implementation
- **Performance:** 85-88% expected
- **Why Apex:** Self-reinforcing positive feedback - successful hunters recruit more hunters (force multiplier)
- **PettingZoo Fit:**
  - Stigmergy blackboard naturally implements pheromone trails
  - Bounded space concentrates recruitment signals
  - Multi-predator benefits from dynamic force allocation
- **Synergy:** Requires Observer pheromone trails, amplifies Shaper pursuit
- **Implementation:** Agents deposit confidence score in blackboard when close to prey (high confidence = strong recruitment)

#### 7. **Bee Waggle Dance Vector Encoding**
- **Source:** Von Frisch 1967 (Honeybee spatial communication)
- **Type:** Biological - Social insect navigation
- **Status:** üü° Pending implementation
- **Performance:** 83-86% expected
- **Why Apex:** Direction/distance encoding (not absolute position) - robust to partial observability
- **PettingZoo Fit:**
  - Partial observability requires relative encoding
  - Obstacles obscure absolute positions
  - Vector representation maintains information under occlusion
- **Synergy:** Works with Observer for distributed sensing
- **Implementation:** Blackboard stores vector to prey (angle + magnitude), not absolute coordinates

#### 8. **Lion Pride Silent Coordination**
- **Source:** Stander 1992 (Visual coordination without vocalization)
- **Type:** Biological - Feline pack hunters
- **Status:** üü° Pending implementation
- **Performance:** 84-87% expected
- **Why Apex:** Robust to communication failure - lionesses form triangular ambush purely from observing each other's positions
- **PettingZoo Fit:**
  - Stigmergy failures require fallback coordination
  - Bounded space enables visual coordination range
  - Triangle formation naturally emerges from relative positioning
- **Synergy:** Standalone (emergent), but amplified by Bridger consensus
- **Implementation:** React to other predator positions to form triangle around prey (no explicit comms)

### Shaper Role (ACT Layer - Fires/Maneuver)

#### 9. **Potential Field Navigation** ‚≠ê S-TIER
- **Source:** Khatib 1986 (Real-time obstacle avoidance robotics)
- **Type:** Industry/Robotics (bio-inspired from bacterial chemotaxis)
- **Status:** ‚úÖ Implemented & Tested (300 episodes)
- **Performance:** 90.7% catch rate (S-TIER champion)
- **Why Apex:** Emergent coordination through force field summation - smooth paths with natural obstacle avoidance
- **PettingZoo Fit:**
  - Obstacles = repellers (automatic avoidance)
  - Prey = attractor (pursuit gradient)
  - Agents = weak repellers (anti-clustering)
  - Bounded walls = strong repellers (containment)
- **Synergy:** Standalone emergent coordination (no explicit C2 needed)
- **Implementation:** `force = Œ£(attract_prey - repel_obstacle - repel_agent); move along gradient`
- **Parameters:** `attraction_repulsion_ratio=0.1, repulsion_threshold=0.3`

#### 10. **Wolf Pack Encirclement**
- **Source:** Mech & Boitani 2003 (Coordinated wolf hunting)
- **Type:** Biological - Canine pack tactics
- **Status:** ‚úÖ Implemented & Tested (300 episodes)
- **Performance:** 83% catch rate (B-TIER)
- **Why Apex:** Wide arc formation with gradual tightening - prevents early escape
- **PettingZoo Fit:**
  - Bounded space limits escape routes (arc compression effective)
  - Obstacles provide natural chokepoints for arc positioning
  - Multi-predator coordination creates inescapable zones
- **Synergy:** May improve with Navigator tightening control parameter tuning
- **Implementation:** Start at 0.5 distance, converge to 0.15 over `tightening_cycles=15`
- **Parameters:** `formation_distance=0.121` (QD champion discovery)

#### 11. **Military Envelopment (ATP-3-60)**
- **Source:** ATP-3-60 Chapter 3 (Double Envelopment doctrine)
- **Type:** Military - Combined arms maneuver
- **Status:** ‚úÖ Implemented & Tested (300 episodes)
- **Performance:** 84.3% catch rate (B-TIER)
- **Why Apex:** Simultaneous multi-directional attack - cuts all escape routes
- **PettingZoo Fit:**
  - 3 predators form 120¬∞ triangle spacing (perfect for 3-agent team)
  - Obstacles prevent prey from breaking through encirclement gaps
  - Bounded space ensures closing formation traps prey
- **Synergy:** Fixed geometry may improve with dynamic Navigator adjustment
- **Implementation:** 3 agents positioned at 120¬∞ intervals around prey, maintain spacing

#### 12. **Dolphin Spiral Herding**
- **Source:** Benoit-Bird & Au 2009 (Cooperative dolphin prey herding)
- **Type:** Biological - Marine mammal tactics
- **Status:** üü° Pending implementation
- **Performance:** 85-88% expected
- **Why Apex:** Spiral inward compression - contains prey without direct contact until final strike
- **PettingZoo Fit:**
  - Bounded space amplifies compression effectiveness
  - Obstacles create pressure points during spiral
  - No stamina allows sustained circular orbiting
- **Synergy:** Requires Bridger for spiral coordination
- **Implementation:** Circular orbit around prey, decrease radius by fixed amount per cycle

#### 13. **Orca Bubble Net Wall**
- **Source:** Sharpe & Dill 1997 (Orca cooperative hunting)
- **Type:** Biological - Marine mammal complex tactics
- **Status:** üü° Pending implementation
- **Performance:** 84-87% expected
- **Why Apex:** Create barrier to funnel prey - reduces 2D escape to 1D (easier intercept)
- **PettingZoo Fit:**
  - Agents form line perpendicular to prey escape vector
  - Obstacles amplify barrier effect (combined blockade)
  - Bounded space limits prey evasion options
- **Synergy:** Works with Observer to predict escape vector, Shaper to position barrier
- **Implementation:** Line formation perpendicular to prey velocity vector

#### 14. **Lion Ambush Positioning**
- **Source:** Stander 1992 (Lion pride ambush tactics)
- **Type:** Biological - Feline stealth predation
- **Status:** üü° Pending implementation
- **Performance:** 82-85% expected
- **Why Apex:** Surprise attack from concealment - wait until prey enters kill zone
- **PettingZoo Fit:**
  - Obstacles provide concealment positions
  - Bounded space ensures prey eventually enters ambush zone
  - Patience tactical option (wait vs chase)
- **Synergy:** Requires Observer for prey path prediction
- **Implementation:** Position ahead of predicted prey path near obstacles, wait until distance < 0.2

#### 15. **African Wild Dog Sprint Relay**
- **Source:** Creel & Creel 1995 (Relay hunting tactics)
- **Type:** Biological - Canine endurance hunters
- **Status:** üü° Pending implementation
- **Performance:** Unknown (requires stamina modeling)
- **Why Apex:** Role rotation for sustained pursuit - fresh hunters take over from tired ones
- **PettingZoo Fit:**
  - **Modified for no-stamina:** Role rotation based on proximity/position rather than fatigue
  - Bounded space allows rapid role handoffs
  - Multi-predator benefits from dynamic role assignment
- **Synergy:** Requires Navigator role assignment (who sprints, who blocks)
- **Implementation:** Closest predator = active pursuer, others position for intercept/cutoff

#### 16. **Dolphin Strand Feeding Coordination**
- **Source:** Lewis & Schroeder 2003 (Beach-herding dolphins)
- **Type:** Biological - Marine mammal environmental exploitation
- **Status:** üü° Pending implementation
- **Performance:** Unknown
- **Why Apex:** Use environment boundary as weapon - drive prey into wall/corner
- **PettingZoo Fit:**
  - Bounded space walls are explicit boundaries (like beach)
  - Obstacles create additional trap zones
  - Coordinated herding toward wall = guaranteed capture
- **Synergy:** Requires Bridger spatial coordination for synchronized herding
- **Implementation:** Agents coordinate to drive prey toward nearest wall/obstacle, compress against boundary

### Immunizer Role (BLUE TEAM - Force Protection)

#### 17. **Clonal Selection Adaptive Defense**
- **Source:** De Castro & Von Zuben 2002 (Artificial Immune System)
- **Type:** Biological - Immune system adaptation
- **Status:** üü° Pending implementation
- **Performance:** Unknown (defensive primitive)
- **Why Apex:** Adaptive pattern recognition - learns and amplifies successful defensive responses
- **PettingZoo Fit:**
  - Defensive evasion when predator roles reversed
  - Adaptive response to repeated attack patterns
  - Pattern library for counter-tactics
- **Synergy:** Requires Disruptor red team for training effective defenses
- **Implementation:** Maintain library of successful evasion patterns, clone/amplify when pattern matches current threat

#### 18. **Bee Guard Nest Defense**
- **Source:** Moore et al. 1987 (Honeybee alarm pheromone response)
- **Type:** Biological - Social insect collective defense
- **Status:** üü° Pending implementation
- **Performance:** 12% documented effectiveness (low baseline)
- **Why Apex:** **Included for QD synergy testing** - known low individual performer may combine with other primitives for emergent effectiveness
- **PettingZoo Fit:**
  - Alarm signal propagation via stigmergy
  - Coordinated defensive response to intrusion
  - Territory protection in bounded space
- **Synergy:** Test for unexpected synergies with other roles (QD principle: 20% + 20% may = 90%)
- **Implementation:** Broadcast alarm when threatened, swarm response from nearby agents

### Disruptor Role (RED TEAM - Adversarial Testing)

#### 19. **MITRE ATT&CK Simulation**
- **Source:** MITRE ATT&CK Framework (Adversarial tactics database)
- **Type:** Military - Cyber/physical red team methodology
- **Status:** üü° Pending implementation
- **Performance:** Unknown (adversarial testing primitive)
- **Why Apex:** Systematic attack pattern discovery - tests defense robustness
- **PettingZoo Fit:**
  - Generate adversarial prey behaviors to stress-test predator tactics
  - Discover edge cases in bounded space (corner traps, obstacle exploits)
  - Validate primitive robustness
- **Synergy:** Requires Immunizer to test and harden defenses
- **Implementation:** Library of attack patterns (jinking, wall-hugging, obstacle-hiding), systematically test predator responses

#### 20. **Somatic Hypermutation Pattern Generation**
- **Source:** Tonegawa 1983 (Antibody diversity via genetic recombination)
- **Type:** Biological - Immune system evolution
- **Status:** üü° Pending implementation
- **Performance:** Unknown (diversity generation)
- **Why Apex:** Generates novel attack variants - discovers unknown vulnerabilities
- **PettingZoo Fit:**
  - Mutate prey behaviors to find predator blind spots
  - Generate edge case scenarios in obstacle configurations
  - QD-style diversity search for failure modes
- **Synergy:** Feeds novel patterns to Immunizer for defensive training
- **Implementation:** Mutate successful evasion behaviors (Gaussian noise on parameters), test variants

### Infuser Role (SUSTAINMENT - Logistics)

#### 21. **Physarum Network Optimization**
- **Source:** Tero et al. 2010 (Slime mold efficient network design)
- **Type:** Biological - Cellular computation
- **Status:** üü° Pending implementation
- **Performance:** Unknown (resource routing)
- **Why Apex:** Optimal resource flow through network - slime mold recreates Tokyo subway efficiency
- **PettingZoo Fit:**
  - **Adapted for multi-swarm L1+** operations (beyond single hunt)
  - Route coordination signals efficiently through stigmergy network
  - Optimize communication bandwidth in multi-agent systems
- **Synergy:** Enables complex multi-swarm scenarios (future capability)
- **Implementation:** Adaptive network graph where successful paths strengthen, unused paths weaken

#### 22. **Ant Trophallaxis Resource Sharing**
- **Source:** H√∂lldobler & Wilson 1990 (Ant food sharing)
- **Type:** Biological - Social insect logistics
- **Status:** üü° Pending implementation
- **Performance:** Unknown (resource distribution)
- **Why Apex:** Decentralized resource redistribution - ensures no agent starves/overloads
- **PettingZoo Fit:**
  - **Adapted for information sharing** (not physical resources in simple_tag)
  - Distribute sensing information among agents
  - Load balancing of computational roles
- **Synergy:** Enables fractal propagation of knowledge (20-30% efficiency per hop)
- **Implementation:** Agents share state information with neighbors, propagate through network

### Analyzer Role (ASSESSMENT - Battle Damage Assessment)

#### 23. **SRE Error Budget Assessment**
- **Source:** Google SRE Book (Service level objectives framework)
- **Type:** Industry - Site reliability engineering
- **Status:** üü° Pending implementation
- **Performance:** Unknown (continuous improvement)
- **Why Apex:** Quantified acceptable failure rate - enables risk-taking within bounds
- **PettingZoo Fit:**
  - Track catch rate vs target (‚â•90%)
  - Allocate "error budget" for experimental primitives
  - Guide primitive selection based on performance gaps
- **Synergy:** Feeds learning into Navigator for strategy adjustment
- **Implementation:** Track rolling window performance, signal when below SLO threshold

#### 24. **F3EAD Cycle Analysis**
- **Source:** ATP-2-01 (Intelligence operations - Find, Fix, Finish, Exploit, Analyze, Disseminate)
- **Type:** Military - Intelligence cycle
- **Status:** üü° Pending implementation
- **Performance:** Unknown (strategic learning)
- **Why Apex:** Systematic learning extraction from outcomes - military gold standard for operational learning
- **PettingZoo Fit:**
  - Analyze successful hunts to extract reusable patterns
  - Disseminate learnings via stigmergy to other agents/swarms
  - Build institutional knowledge from experience
- **Synergy:** Strategic feedback loop for continuous improvement
- **Implementation:** Post-episode analysis extracts features of successful catches, stores in pattern library

### Navigator Role (ORCHESTRATION - Multi-Swarm C2)

#### 25. **Ant Task Allocation Switching**
- **Source:** Gordon 2011 (Decentralized task switching in ant colonies)
- **Type:** Biological - Social insect coordination
- **Status:** üü° Pending implementation
- **Performance:** Unknown (C2 primitive)
- **Why Apex:** Decentralized role assignment without central controller - ants switch tasks based on local cues
- **PettingZoo Fit:**
  - Assign roles dynamically (who chases, who blocks, who scouts)
  - Respond to local conditions (prey proximity, obstacle density)
  - No central C2 node (robust to single-point failure)
- **Synergy:** Core Navigator capability - enables other primitives to coordinate
- **Implementation:** Task probabilities based on local state (close to prey ‚Üí chase role, far ‚Üí scout role)

#### 26. **QD Formation Distance Parameter**
- **Source:** HFO QD Gen 33 Discovery (MAP-Elites breeding)
- **Type:** Geometric/QD - Evolutionary discovery
- **Status:** ‚úÖ Implemented (as part of Wolf Encirclement)
- **Performance:** 88.3% catch rate (QD Champion parameter)
- **Why Apex:** Discovered optimal spacing parameter - MAP-Elites found `formation_distance=0.121` superior to human-designed values
- **PettingZoo Fit:**
  - Optimal agent spacing for bounded environment
  - Prevents clustering while maintaining coverage
  - Discovered empirically for exact PettingZoo configuration
- **Synergy:** Combines with Potential Field (90.7%) for potential synergistic boost
- **Implementation:** Used in Wolf Encirclement and other formation-based primitives

#### 27. **Mosaic Warfare Tile Reconfiguration**
- **Source:** JP-5-0 (Joint planning process - Mosaic warfare concept)
- **Type:** Military - Modern network-centric warfare
- **Status:** üü° Pending implementation
- **Performance:** Unknown (L1+ multi-swarm)
- **Why Apex:** Dynamic force composition - recombine assets on-the-fly for emergent capabilities
- **PettingZoo Fit:**
  - **Future capability for multi-swarm scenarios**
  - Reconfigure 3-predator team into different formations
  - Adaptive composition based on prey behavior
- **Synergy:** Requires multi-layer coordination (beyond single hunt)
- **Implementation:** Modular primitive composition, swap primitives based on performance feedback

---

## ü§ñ ROBOTIC/INDUSTRY PRIMITIVES

### Observer Role (Sensing/Estimation)

#### 28. **Kalman Filter Optimal Estimation**
- **Source:** Kalman 1960 / Welch & Bishop 1995 (Aerospace standard)
- **Type:** Industry/Robotics
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 86% catch rate (validated)
- **Why Apex:** Optimal state estimation with uncertainty quantification - aerospace gold standard
- **PettingZoo Fit:**
  - Noisy observations from partial visibility
  - Optimal prediction of prey position/velocity
  - Bounded space provides process model constraints
- **Synergy:** May combine with Wolf Visual Lock for hybrid filtering
- **Implementation:** Standard 2D position/velocity Kalman filter with constant velocity model

#### 29. **Particle Filter Monte Carlo Sampling**
- **Source:** Thrun et al. 2005 (Probabilistic Robotics)
- **Type:** Industry/Robotics
- **Status:** üü° Pending implementation
- **Performance:** 84-87% expected
- **Why Apex:** Multi-modal distribution handling - better than Kalman when prey has multiple possible locations
- **PettingZoo Fit:**
  - Obstacles create multi-modal possibilities (prey could be behind any obstacle)
  - Handles non-Gaussian uncertainty
  - Particle resampling focuses computation on likely regions
- **Synergy:** Superior to Kalman for ambiguous situations (prey at fork point)
- **Implementation:** 100 particles sampling possible prey states, resample by observation likelihood

### Bridger Role (Coordination/Arbitration)

#### 30. **Voronoi Tessellation Territory**
- **Source:** Fortune 1987 / Okabe et al. 2000 (Computational geometry)
- **Type:** Industry/Robotics
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 83% catch rate (validated)
- **Why Apex:** Dynamic spatial ownership - each agent responsible for nearest region
- **PettingZoo Fit:**
  - Bounded space naturally tessellates into regions
  - Obstacles create complex Voronoi boundaries
  - Automatic load balancing (agents spread to cover space)
- **Synergy:** Requires Navigator for territory assignment and handoff
- **Implementation:** Compute Voronoi cells for predator positions, each agent pursues prey in their cell

#### 31. **Consensus Voting (Raft Algorithm)**
- **Source:** Ongaro & Ousterhout 2014 (Distributed consensus)
- **Type:** Industry - Distributed systems
- **Status:** üü° Pending implementation
- **Performance:** 85-88% expected
- **Why Apex:** Fault-tolerant state agreement - majority vote filters outliers
- **PettingZoo Fit:**
  - Robust to observation noise/failures
  - 3 predators vote on prey position (median wins)
  - Filters erroneous observations from occlusion
- **Synergy:** Works with Observer to fuse multiple noisy observations
- **Implementation:** Each agent votes on prey position, take median (or mode) as consensus

#### 32. **Leader Election (Bully Algorithm)**
- **Source:** Garc√≠a-Molina 1982 (Distributed systems)
- **Type:** Industry - Distributed systems
- **Status:** üü° Pending implementation
- **Performance:** 86-89% expected
- **Why Apex:** Adaptive leadership - highest fitness agent becomes temporary coordinator
- **PettingZoo Fit:**
  - Closest predator becomes leader (temporary C2)
  - Leader directs formation, others execute
  - Dynamic handoff as positions change
- **Synergy:** Enables centralized tactics without fixed C2 node
- **Implementation:** Agent closest to prey broadcasts intended action, others form around it

---

## üéñÔ∏è MILITARY DOCTRINE PRIMITIVES

### Observer Role (ISR - Intelligence, Surveillance, Reconnaissance)

#### 33. **Multi-Source Fusion (ATP-3-55 Ch.3)**
- **Source:** ATP-3-55 (US Army Information Collection doctrine)
- **Type:** Military - ISR operations
- **Status:** üü° Pending implementation
- **Performance:** 85-88% expected
- **Why Apex:** Combine visual + communication signals - redundancy reduces observation noise
- **PettingZoo Fit:**
  - Fuse direct observation + stigmergic blackboard signals
  - Multiple predators provide redundant observations
  - Cross-validation filters noise
- **Synergy:** Requires stigmergy infrastructure (already implemented)
- **Implementation:** Weight direct observation + blackboard reports, Bayesian fusion

#### 34. **Pattern-of-Life Analysis (ATP-3-55 Ch.4)**
- **Source:** ATP-3-55 Chapter 4
- **Type:** Military - Intelligence analysis
- **Status:** üü° Pending implementation
- **Performance:** 84-87% expected
- **Why Apex:** Model prey behavior over time - extract movement signature for prediction
- **PettingZoo Fit:**
  - Bounded space creates repeatable prey patterns
  - History buffer (5-10 steps) captures movement signature
  - Predict habitual behaviors (wall-following, corner preference)
- **Synergy:** Works with Analyzer to build pattern library
- **Implementation:** Sliding window velocity analysis, extract turning frequency, predict next move

#### 35. **Predictive Intelligence (ATP-3-55 Ch.5)**
- **Source:** ATP-3-55 Chapter 5
- **Type:** Military - Intelligence operations
- **Status:** üü° Pending implementation
- **Performance:** 86-89% expected
- **Why Apex:** Anticipate future position based on intent (not just velocity) - beats linear extrapolation
- **PettingZoo Fit:**
  - Intelligent prey have goals (flee toward exit, hide behind obstacle)
  - Bayesian intent inference improves prediction
  - Obstacles reveal prey intent (heading toward cover vs open space)
- **Synergy:** Superior to simple velocity extrapolation for intelligent prey
- **Implementation:** Infer prey goal (nearest exit, cover, center), predict path toward goal

#### 36. **Denied-Area Sensing (ATP-3-55 Ch.6)**
- **Source:** ATP-3-55 Chapter 6
- **Type:** Military - ISR in contested environments
- **Status:** üü° Pending implementation
- **Performance:** 85-88% expected
- **Why Apex:** Wall/obstacle awareness in prediction - don't predict prey into walls
- **PettingZoo Fit:**
  - Obstacles create denied areas (prey cannot occupy)
  - Ray-casting to walls validates predictions
  - Penalize predictions into obstacles (invalid states)
- **Synergy:** Improves all prediction primitives (Kalman, Particle Filter, Raptor Dive)
- **Implementation:** Ray-cast from predicted positions, reject if collision detected

### Bridger Role (C2 - Command & Control)

#### 37. **Common Operational Picture (JP-6-0 Ch.2)**
- **Source:** JP-6-0 (Joint Communications System doctrine)
- **Type:** Military - C2 fusion
- **Status:** ‚úÖ Implemented & Tested (L1 Stigmergy)
- **Performance:** 87% catch rate (L1 validated)
- **Why Apex:** Shared state across all agents - COP is foundation of modern multi-domain operations
- **PettingZoo Fit:**
  - Stigmergic blackboard implements COP
  - All predators see same prey state
  - Asynchronous updates (TTL-based freshness)
- **Synergy:** Foundation for all multi-agent coordination
- **Implementation:** Blackboard with prey position, velocity, agent states, TTL expiration

#### 38. **De-Confliction Arbitration (JP-6-0 Ch.3)**
- **Source:** JP-6-0 Chapter 3
- **Type:** Military - Airspace/route management
- **Status:** üü° Pending implementation
- **Performance:** 86-89% expected
- **Why Apex:** Collision avoidance via priority - prevents clustering, maintains spacing
- **PettingZoo Fit:**
  - 3 predators naturally cluster on prey (inefficient)
  - Priority arbitration (agent ID: 0>1>2, lower yields)
  - Maintains optimal spacing automatically
- **Synergy:** Complements formation primitives (Wolf, Envelopment)
- **Implementation:** If agents too close (<threshold), lower priority agent yields (moves away)

#### 39. **Priority-Based Tasking (JP-6-0 Ch.4)**
- **Source:** JP-6-0 Chapter 4
- **Type:** Military - Task allocation
- **Status:** üü° Pending implementation
- **Performance:** 87-90% expected
- **Why Apex:** Dynamic role assignment - closest chases, others block escape routes
- **PettingZoo Fit:**
  - Better division of labor than fixed roles
  - Adapts to prey movement (new closest = new chaser)
  - Blockers position at predicted escape vectors
- **Synergy:** Core coordination primitive for many tactics
- **Implementation:** Closest agent = chaser role, others compute escape vectors and block

#### 40. **Commander's Intent Propagation (JP-6-0 Ch.5)**
- **Source:** JP-6-0 Chapter 5 (Mission command)
- **Type:** Military - Decentralized execution
- **Status:** üü° Pending implementation
- **Performance:** 86-89% expected
- **Why Apex:** Mission-type orders (goal, not method) - adaptive coordination without micromanagement
- **PettingZoo Fit:**
  - Blackboard broadcasts "ENCIRCLE" or "CHASE" mode
  - Agents adapt execution locally (how to encircle based on position)
  - Robust to communication delays
- **Synergy:** Enables high-level coordination with local autonomy
- **Implementation:** Mode variable in blackboard, agents select tactics based on mode + local state

### Shaper Role (Fires - Kinetic/Non-Kinetic Effects)

#### 41. **Fixed Angle Formation (ATP-3-60 Ch.2)**
- **Source:** ATP-3-60 (Targeting doctrine)
- **Type:** Military - Fire support coordination
- **Status:** ‚úÖ Implemented & Tested (L1)
- **Performance:** 87% catch rate (L1 validated)
- **Why Apex:** Pre-defined spatial roles - simple, robust, effective
- **PettingZoo Fit:**
  - 3 predators at fixed angles (north, south, east of prey)
  - Bounded space ensures formation containment
  - Obstacles integrated as additional blockers
- **Synergy:** Baseline formation primitive
- **Implementation:** Assign agents to 0¬∞, 120¬∞, 240¬∞ positions around prey

#### 42. **Blocking Positions (ATP-3-60 Ch.4)**
- **Source:** ATP-3-60 Chapter 4 (Fire support)
- **Type:** Military - Maneuver control
- **Status:** ‚úÖ Implemented & Tested (A4)
- **Performance:** 83% catch rate (A4 validated)
- **Why Apex:** Cut escape routes - deny prey freedom of maneuver
- **PettingZoo Fit:**
  - Agents position between prey and nearest exit
  - Obstacles create natural chokepoints for blocking
  - Bounded space has limited exits (enumerate and block)
- **Synergy:** Works with Observer to predict escape vectors
- **Implementation:** Compute prey escape vectors, position agents to intercept

#### 43. **Fire & Maneuver Bounding Overwatch (ATP-3-60 Ch.5)**
- **Source:** ATP-3-60 Chapter 5
- **Type:** Military - Infantry tactics
- **Status:** üü° Pending implementation
- **Performance:** 85-88% expected
- **Why Apex:** One element fixes, another flanks - prevents prey from predicting all threats
- **PettingZoo Fit:**
  - 2 predators chase directly (fix prey attention)
  - 1 predator wide flank (unpredictable angle)
  - Prey cannot optimize against both threats
- **Synergy:** Requires role assignment (Navigator)
- **Implementation:** 2 agents pursue, 1 agent circles to perpendicular angle for flanking attack

---

## üî∑ GEOMETRIC/QD DISCOVERED PRIMITIVES

#### 44. **QD Tighter Formation**
- **Source:** MAP-Elites QD breeding (HFO Gen 33)
- **Type:** Geometric optimization via evolutionary search
- **Status:** üü° Implemented (as variant)
- **Performance:** Unknown (QD artifact, not baseline tested)
- **Why Apex:** Discovered through quality diversity search - may contain non-obvious optimizations
- **PettingZoo Fit:**
  - Empirically tuned for exact PettingZoo environment
  - Parameters discovered by MAP-Elites, not human design
  - Potential for synergistic combinations
- **Synergy:** Test with other primitives for emergent behaviors
- **Implementation:** Formation primitive with QD-discovered spacing/timing parameters

#### 45. **Explore/Exploit 2/8 Seed**
- **Source:** User specification (problem statement seed)
- **Type:** Geometric/Strategic - Search strategy
- **Status:** üü° Strategy parameter (not primitive)
- **Performance:** Unknown (meta-parameter)
- **Why Apex:** Balances exploration (search space diversity) vs exploitation (refine best)
- **PettingZoo Fit:**
  - 20% time exploring new behaviors
  - 80% time exploiting known good behaviors
  - Prevents premature convergence on local optimum
- **Synergy:** Applies across all primitives during QD breeding
- **Implementation:** In training: 20% random primitive selection, 80% select from top performers

---

## üéØ INTEGRATION WITH SWARMLORD C2 + VIRTUAL STIGMERGY

**Key Principle:** All primitives are **building blocks** that achieve apex performance when wrapped with coordination infrastructure.

### Swarmlord C2 Commander Wrapper
- **Role:** Tactical interface between Overmind directives and primitive execution
- **Functions:**
  - Primitive selection based on prey behavior classification
  - Parameter tuning based on environment state (obstacle density, pursuit phase)
  - Mode switching (HUNT ‚Üí ENCIRCLE ‚Üí STRIKE transitions)
  - BLUF reporting to Overmind (escalation triggers)

### Virtual Stigmergy Coordination Layer
- **Implementation:** Blackboard architecture with TTL-based freshness
- **Data Structures:**
  ```json
  {
    "role": "observer",
    "event": "prey_detected", 
    "data": {"position": [0.5, 0.3], "velocity": [-0.1, 0.2]},
    "confidence": 0.9,
    "ttl": 3600,
    "next_role": "bridger"
  }
  ```
- **Coordination Patterns:**
  - **Observer ‚Üí Bridger:** Sensing data fusion
  - **Bridger ‚Üí Shaper:** Coordinated action selection
  - **Shaper ‚Üí Analyzer:** Outcome assessment
  - **Analyzer ‚Üí Navigator:** Strategic adjustment
  - **Navigator ‚Üí Observer:** Focus sensing (close loop)

### OBSIDIAN Role Taxonomy (8 Roles)
| Role | JADC2 Equivalent | Primitives Count | Example |
|------|------------------|------------------|---------|
| Observer | ISR | 7 | Raptor Dive, Kalman Filter |
| Bridger | C2 Fusion | 8 | Stigmergy COP, Voronoi |
| Shaper | Fires | 12 | Potential Field, Wolf Pack |
| Immunizer | Force Protection | 2 | Clonal Selection |
| Disruptor | Red Team | 2 | MITRE ATT&CK |
| Infuser | Sustainment | 2 | Physarum Network |
| Analyzer | BDA | 2 | SRE Error Budget |
| Navigator | Strategic C2 | 3 | Ant Task Allocation |

**Total:** 38+ primitives (some multi-role)

---

## üìà TESTING ROADMAP FOR PETTINGZOO

### Phase 1: Baseline Validation (CURRENT)
- ‚úÖ Potential Field: 90.7% (S-TIER)
- ‚úÖ Wolf Encirclement: 83% (B-TIER)
- ‚úÖ Envelopment: 84.3% (B-TIER)
- ‚úÖ Kalman Filter: 86%
- ‚úÖ Voronoi: 83%
- ‚úÖ L1 Stigmergy COP: 87%
- ‚úÖ L1 Fixed Angles: 87%
- ‚úÖ A4 Blocking: 83%

**Current Best:** Potential Field 90.7% (near target ‚â•90%)

### Phase 2: High-Priority Untested (NEXT)
Implement top expected performers:
1. Raptor Dive Intercept (87-90%)
2. Priority-Based Tasking (87-90%)
3. Predictive Intelligence (86-89%)
4. Leader Election (86-89%)

**Goal:** Find primitives that exceed 90% standalone or in combination

### Phase 3: QD Synergy Testing
- Test low performers (Bee Guard 12%) in combinations
- MAP-Elites breeding of primitive combinations
- Discover emergent synergies (20% + 20% = 90%?)
- Validate QD hypothesis: optimal role distribution unknown (Navigator might need 20 primitives, Observer might need 2)

### Phase 4: Complete Library (84% Untested)
- Implement all 27 pending primitives
- 300 episodes each vs DDPG pretrained prey
- Performance matrix complete
- QD archive with all primitives as base population

---

## üéì WHY THESE ARE "APEX" PRIMITIVES

### Biological Apex Criteria
- **Proven in nature:** Millions of years of evolution (wolves, raptors, dolphins, ants)
- **High success rates:** Apex predators have >80% hunt success in natural environments
- **Adaptable:** Work across diverse terrains (bounded space = territory constraint found in nature)
- **Coordinated:** Pack/pod/colony tactics scale to multi-agent systems

### Military Apex Criteria
- **Doctrine-validated:** ATP/JP publications are distilled best practices from decades of combat
- **Multi-domain:** ISR + C2 + Fires integration (complete kill chain)
- **Force multiplier:** Coordination primitives amplify individual capabilities
- **Battle-tested:** Proven in real-world operations (not just simulations)

### Robotic/Industry Apex Criteria
- **Mathematically optimal:** Kalman filter = provably optimal estimation under Gaussian assumptions
- **Production-hardened:** Used in aerospace, self-driving cars, robotics (billion-dollar stakes)
- **Real-time capable:** Efficient computation for online decision-making
- **Robust:** Handle noise, uncertainty, failures gracefully

### Geometric/QD Criteria
- **Empirically discovered:** Not human-designed - found through search
- **Diversity preservation:** QD maintains variety (important for synergy testing)
- **Non-obvious:** May contain insights not accessible to human intuition
- **Environment-specific:** Tuned for exact PettingZoo configuration

---

## üöÄ PETTINGZOO MISSION FIT ANALYSIS

### Environment Constraints
- **Bounded Space:** 1x1 continuous space (walls at boundaries)
- **Obstacles:** 2 circular obstacles (create occlusion, chokepoints)
- **No Stamina:** Agents can move at max speed continuously
- **Partial Observability:** Agents see relative positions within range (not global state)
- **3 Predators vs 1 Prey:** Asymmetric team sizes (coordination crucial)
- **Max 100 Cycles:** Finite horizon (time pressure)

### Why Primitives Excel in This Environment

#### Bounded Space Advantages
- **Encirclement tactics effective:** Prey cannot flee infinitely (Wolf, Envelopment, Dolphin Spiral)
- **Prediction easier:** Finite state space limits prey options (Pattern-of-Life, Raptor Dive)
- **Wall exploitation:** Boundary as weapon (Dolphin Strand Feeding, blocking at walls)

#### Obstacle Advantages
- **Chokepoints emergent:** Natural funnel points for ambush (Lion Ambush, Orca Bubble Net)
- **Occlusion creates challenge:** Benefits sensor fusion (Multi-Source Fusion, Consensus Voting)
- **Denied areas:** Obstacles create prediction constraints (Denied-Area Sensing)

#### No Stamina Advantages
- **Sustained pursuit viable:** Continuous chase without fatigue penalty (Raptor Dive, Chase heuristics)
- **Formation maintenance:** Can hold positions indefinitely (Envelopment, Fixed Angles)
- **Spiral tactics:** Circular orbits sustainable (Dolphin Spiral Herding)

#### Partial Observability Advantages
- **Coordination essential:** Single agent view insufficient (all Bridger primitives)
- **Communication valuable:** Stigmergy provides force multiplier (COP, Ant Recruitment)
- **Fusion critical:** Multiple observations reduce uncertainty (Multi-Source, Kalman, Particle Filter)

#### 3v1 Asymmetry Advantages
- **Role specialization:** Enough agents for distinct roles (scout, chaser, blocker)
- **Triangle formations:** 3 agents naturally form stable triangle (Envelopment, Wolf, Fixed Angles)
- **Redundancy:** Agent loss doesn't doom mission (fault tolerance)

---

## üìö REFERENCES

### Military Doctrine
- ATP-3-55: US Army Information Collection (2015)
- ATP-3-60: Targeting (2015)
- JP-6-0: Joint Communications System (2022)
- JP-5-0: Joint Planning (2020)
- ATP-2-01: Intelligence Operations (2021)
- MITRE ATT&CK Framework (2023)

### Biological Research
- H√∂lldobler & Wilson (1990): *The Ants* - Ant colony optimization, pheromones, trophallaxis
- Mech & Boitani (2003): *Wolves: Behavior, Ecology, Conservation* - Wolf pack hunting dynamics
- Stander (1992): Cooperative Hunting in Lions - Silent coordination, pride tactics
- Benoit-Bird & Au (2009): Cooperative Prey Herding by the Pelagic Dolphin
- Sharpe & Dill (1997): The Behavior of Pacific Herring Schools in Response to Artificial Humpback Whale Bubbles
- Shifferman & Eilam (2004): Raptor hunting optimization
- Creel & Creel (1995): African Wild Dog relay hunting
- Lewis & Schroeder (2003): Dolphin strand feeding
- Von Frisch (1967): Bee waggle dance communication
- Au & Hastings (2008): Dolphin echolocation
- De Castro & Von Zuben (2002): Artificial Immune Systems (Clonal Selection)
- Tonegawa (1983): Somatic Hypermutation (Nobel Prize)
- Moore et al. (1987): Honeybee alarm pheromone and defense behavior
- Tero et al. (2010): Rules for Biologically Inspired Adaptive Network Design (Physarum)
- Gordon (2011): The Evolution of the Algorithms for Collective Behavior (Ant task allocation)

### Industry/Robotics
- Kalman (1960): A New Approach to Linear Filtering and Prediction Problems
- Welch & Bishop (1995): An Introduction to the Kalman Filter
- Thrun et al. (2005): *Probabilistic Robotics* - Particle filters, localization
- Khatib (1986): Real-Time Obstacle Avoidance for Manipulators and Mobile Robots (Potential Fields)
- Okabe et al. (2000): *Spatial Tessellations* - Voronoi diagrams
- Fortune (1987): A Sweepline Algorithm for Voronoi Diagrams
- Ongaro & Ousterhout (2014): In Search of an Understandable Consensus Algorithm (Raft)
- Garc√≠a-Molina (1982): Elections in a Distributed Computing System (Bully Algorithm)
- Google SRE Book (2016): Site Reliability Engineering - Error budgets, SLOs

### PettingZoo/Testing
- Terry et al. (2021): PettingZoo: Gym for Multi-Agent Reinforcement Learning
- Gupta et al. (2017): Cooperative Multi-Agent Control Using Deep Reinforcement Learning
- EPyMARL: Extended Python MARL framework (DDPG pretrained baselines)

---

## üîÑ NEXT ACTIONS

1. **Implement Priority 1 Primitives** (Expected >87%):
   - Raptor Dive Intercept
   - Priority-Based Tasking
   - Predictive Intelligence
   - Dolphin Spiral Herding

2. **QD Breeding Experiments**:
   - Combine Potential Field (90.7%) + QD Formation (88.3%)
   - Test low performers in combinations (Bee Guard 12% + others)
   - MAP-Elites to discover optimal role distribution

3. **Complete Performance Matrix**:
   - Test all 27 untested primitives (300 episodes each)
   - Document catch rates, timeout rates, avg steps
   - Build empirical database for synergy analysis

4. **Swarmlord Integration**:
   - Wrapper class for primitive selection/switching
   - Parameter tuning based on prey classification
   - BLUF reporting to Overmind with escalation triggers

5. **Export to Other Repo**:
   - Format as importable library
   - Include performance data
   - Provide usage examples with Swarmlord + Stigmergy

---

**Status:** üìä Library Complete | ‚úÖ 5 Tested | üü° 27 Pending | üéØ Target ‚â•90% Catch Rate  
**Coordination:** üï∏Ô∏è Swarmlord C2 + Virtual Stigmergy Wrapper Required  
**Seed:** üå± Explore/Exploit 2/8 for QD Breeding
---
# üï∏Ô∏è‚õ∞Ô∏èüíé PettingZoo Apex Primitives - Complete Categorized List

**Date:** 2025-10-28  
**Purpose:** Complete consolidated list of all HFO apex primitives for PettingZoo test environments  
**Context:** Bounded space with obstacles, no stamina mechanics  
**Coordination:** All primitives wrapped with SwarmlordC2 commander and virtual stigmergy  
**Explore/Exploit Ratio:** 4/6 (40% exploration, 60% exploitation)

---

## üéØ BLUF (Bottom Line Up Front)

This document consolidates **30+ apex primitives** from biological, robotic, geometric, military, and other domains for PettingZoo multi-agent RL testing. Each primitive is categorized by OBSIDIAN role (Observer/Bridger/Shaper/Immunizer/Disruptor/Infuser/Analyzer/Navigator), source domain, and implementation status.

**Key Insights:**
- **Meta-coordination primitives (Tier 1)** vastly outperform individual pursuit optimization (84.2% vs 56.4% mean)
- **Best performer:** Meta_Analyzer (93% S-tier) - first to achieve >90% vs DDPG
- **Most tested:** Shaper primitives (62.5% of total), indicating action-bias in current library
- **Gap to fill:** Disruptor, Infuser, Analyzer roles underrepresented (now addressed in Tier 1)
- **Coordination layer:** Multiple primitives perform poorly alone but excel when coordinated via SwarmlordC2

**PettingZoo Applicability:** All primitives designed for bounded continuous space with obstacles, 3 predator vs 1 prey configuration (simple_tag_v3), max 25-100 cycles per episode.

---

## üìä Implementation Status Matrix

| Category | Total | Implemented | Tested vs Random | Tested vs DDPG | Mean % (DDPG) |
|----------|-------|-------------|------------------|----------------|---------------|
| **Biological** | 16 | 11 | 5 | 11 | 67.8% |
| **Robotic/Industry** | 8 | 6 | 2 | 6 | 63.5% |
| **Geometric/QD** | 5 | 5 | 2 | 5 | 59.6% |
| **Military** | 7 | 5 | 3 | 5 | 68.2% |
| **Meta/Other** | 4 | 4 | 0 | 4 | 84.3% |
| **TOTAL** | **40** | **31** | **12** | **31** | **68.7%** |

---

## üß¨ BIOLOGICAL PRIMITIVES

### ü¶Ö Observer Role (Perception/Sensing)

#### 1. **Raptor Dive Intercept** ‚≠ê TESTED
- **Source:** Shifferman & Eilam 2004 (Raptor hunting)
- **Type:** Time-to-intercept optimal pursuit
- **Status:** ‚úÖ Implemented & Tested (300 eps vs random, 100 eps vs DDPG)
- **Performance:** 85.7% vs random, 54% vs DDPG (A-tier ‚Üí Struggling)
- **Gap:** -31.7% (adaptive prey exploits fixed intercept)
- **Why Apex:** Optimal closing velocity calculation for high-speed intercept
- **PettingZoo Fit:** Bounded space allows clean intercept trajectories, obstacles require evasion mods
- **Coordination:** Standalone effective but benefits from Shaper blocking positions
- **Implementation:** `tests/test_prey_simple_tag_v1_batch1.py::RaptorDiveIntercept`

#### 2. **Wolf Visual Tracking**
- **Source:** Mech & Boitani 2003 (Wolf pack scouting)
- **Type:** Exponential smoothing with high alpha (0.7)
- **Status:** üü° Pending (included in PRIMITIVE_LIBRARY_HUNT.md)
- **Expected:** 85-88%
- **Why Apex:** Sustained pursuit with noise filtering, responsive vs Kalman lag
- **PettingZoo Fit:** Vision-based tracking works in bounded observable space
- **Coordination:** Requires Navigator for pack coordination and role assignment
- **Implementation:** Needed

#### 3. **Ant Pheromone Trail / Scout Trail Memory**
- **Source:** H√∂lldobler & Wilson 1990 (Ant colony optimization)
- **Type:** Spatial heatmap of prey history, weighted toward high-traffic areas
- **Status:** üü° Pending
- **Expected:** 82-85%
- **Why Apex:** Distributed exploration without central coordination, 10-20% scout ratio optimal
- **PettingZoo Fit:** Stigmergy trail works well in bounded grid-like spaces
- **Coordination:** Requires Bridger for signal integration and trail fusion
- **Implementation:** Needed

#### 4. **Dolphin Echolocation (Multi-bounce Sensing)**
- **Source:** Au & Hastings 2008
- **Type:** Environment reflection prediction (wall-bounce detection)
- **Status:** üü° Pending
- **Expected:** 83-86%
- **Why Apex:** Detects wall-bounce maneuvers early via reflection
- **PettingZoo Fit:** Bounded space with obstacles makes wall-bounce critical
- **Coordination:** Enhances other Observer primitives with obstacle awareness
- **Implementation:** Needed

---

### üîó Bridger Role (Signal Fusion/Coordination)

#### 5. **Ant Recruitment** üöÄ BREAKTHROUGH
- **Source:** H√∂lldobler & Wilson 1990 (Pheromone signal integration)
- **Type:** Signal amplification (1 sees ‚Üí all converge)
- **Status:** ‚úÖ Implemented & Tested (100 eps vs DDPG)
- **Performance:** 86% vs DDPG (A-tier), 12.8 avg cycles
- **Expected:** 50-60% ‚Üí **+26% overshoot**
- **Why Apex:** Positive feedback loop for pursuit coordination
- **PettingZoo Fit:** Stigmergic blackboard enables pheromone strength signals
- **Coordination:** Requires Observer pheromone trails for input
- **Implementation:** `agents/bio_ant_recruitment.py`

#### 6. **Kalman Filter 2D** ‚≠ê TESTED
- **Source:** Welch & Bishop 1995 (Aerospace standard)
- **Type:** Optimal state estimation with uncertainty quantification
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 86% vs random (validated), 41% vs DDPG (struggling)
- **Gap:** Large drop indicates DDPG's stochastic evasion defeats prediction
- **Why Apex:** Industry standard for noisy sensor fusion
- **PettingZoo Fit:** Continuous state space, but DDPG trained on stochastic env
- **Coordination:** May improve with Observer sensor fusion
- **Implementation:** `agents/sota_kalman_filter_2d.py`

#### 7. **Voronoi Partition** ‚≠ê TESTED
- **Source:** Fortune 1987 (Computational geometry)
- **Type:** Dynamic spatial ownership, provable coverage
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 83% vs random (validated), 57% vs DDPG
- **Why Apex:** Optimal space partitioning for coverage
- **PettingZoo Fit:** Bounded 2D space ideal for Voronoi tessellation
- **Coordination:** Requires Navigator for territory assignment
- **Implementation:** `agents/sota_voronoi_true.py`

#### 8. **Consensus Voting (Raft-inspired)**
- **Source:** Ongaro & Ousterhout 2014 (Distributed consensus)
- **Type:** Majority vote on prey position, median wins (outlier filtering)
- **Status:** üü° Pending
- **Expected:** 85-88%
- **Why Apex:** Fault tolerance against sensor noise/failures
- **PettingZoo Fit:** Multi-agent coordination requires consensus on shared state
- **Coordination:** Enhances all Observer primitives with robustness
- **Implementation:** Needed

#### 9. **Kalman 5-Step Predictor**
- **Source:** Extended prediction horizon
- **Type:** 5-step lookahead with Kalman smoothing
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 49% vs DDPG (struggling)
- **Why Apex:** Extended prediction for intelligent prey
- **PettingZoo Fit:** Failed vs DDPG's learned stochastic evasion
- **Coordination:** Prediction fails alone, needs reactive Shapers
- **Implementation:** `agents/qd_kalman_5step.py`

---

### ‚öîÔ∏è Shaper Role (Action/Maneuver)

#### 10. **Potential Field** ‚≠ê TESTED - PARADOX
- **Source:** Khatib 1986 (Real-time obstacle avoidance)
- **Type:** Force field (prey = attractor, obstacles/agents = repellers)
- **Status:** ‚úÖ Implemented & Tested (300 eps vs random, 100 eps vs DDPG)
- **Performance:** **90.7% vs random (S-tier, highest!)**, 58% vs DDPG
- **Gap:** **-32.7% (LARGEST DROP)** - adaptive prey exploits static fields
- **Why Apex:** Emergent coordination, smooth obstacle avoidance
- **PettingZoo Fit:** Bounded space with obstacles ideal for force fields
- **Coordination:** Standalone effective vs random, needs dynamic adaptation vs learning
- **Implementation:** `tests/test_prey_simple_tag_v1_batch1.py::PotentialField`

#### 11. **Wolf Pack Encirclement** ‚≠ê TESTED
- **Source:** Mech & Boitani 2003 (Wolf pack hunting)
- **Type:** Wide arc formation, gradual tightening (0.5 ‚Üí 0.15 distance)
- **Status:** ‚úÖ Implemented & Tested (300 eps vs random, 100 eps vs DDPG)
- **Performance:** 83% vs random (B-tier), 53% vs DDPG
- **Gap:** -30%
- **Why Apex:** Natural tightening prevents early escape
- **PettingZoo Fit:** Arc formation works in bounded 2D space
- **Coordination:** May improve with Navigator tightening control
- **Implementation:** `tests/test_prey_simple_tag_v1_batch1.py::WolfEncirclement`

#### 12. **Dolphin Strand Feeding / Herding**
- **Source:** Lewis & Schroeder 2003 (Dolphin cooperative herding)
- **Type:** Spiral inward, compress prey area, circular orbit with decreasing radius
- **Status:** üü° Pending
- **Expected:** 85-88%
- **Why Apex:** Containment without direct contact
- **PettingZoo Fit:** Bounded space enables spiral compression
- **Coordination:** Requires Bridger spatial coordination
- **Implementation:** Needed

#### 13. **Lion Ambush**
- **Source:** Stander 1992 (Lion pride hunting)
- **Type:** Position ahead of prey path, wait until distance < 0.2 (surprise attack)
- **Status:** üü° Pending
- **Expected:** 82-85%
- **Why Apex:** Surprise attack vs continuous chase
- **PettingZoo Fit:** Obstacles provide ambush positions
- **Coordination:** Silent visual coordination (no explicit comms)
- **Implementation:** Needed

#### 14. **Orca Bubble Net**
- **Source:** Sharpe & Dill 1997
- **Type:** Line formation perpendicular to prey escape vector (funnel into trap)
- **Status:** üü° Pending
- **Expected:** 84-87%
- **Why Apex:** Reduces 2D escape to 1D (easier intercept)
- **PettingZoo Fit:** Wall-bounded space creates natural funnel opportunities
- **Coordination:** Requires tight formation coordination
- **Implementation:** Needed

#### 15. **Sprint Intercept (African Wild Dog)**
- **Source:** Creel & Creel 1995 (Relay hunting)
- **Type:** Role assignment (who sprints, who blocks)
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 40% vs DDPG (worst performer)
- **Why Apex:** Relay pursuit exhausts prey over distance
- **PettingZoo Fit:** No stamina in PettingZoo, strategy doesn't apply well
- **Coordination:** Requires Navigator role assignment (critical!)
- **Implementation:** `agents/qd_sprint_intercept.py` (needs redesign)

---

### üõ°Ô∏è Immunizer Role (Force Protection/Filtering)

#### 16. **Clonal Selection (Immune System)** üöÄ BREAKTHROUGH
- **Source:** De Castro & Von Zuben 2002 (Artificial immune system)
- **Type:** Clone successful approaches, discard failures
- **Status:** ‚úÖ Implemented & Tested (100 eps vs DDPG)
- **Performance:** 85% vs DDPG (A-tier)
- **Expected:** 45-55% ‚Üí **+30% overshoot**
- **Why Apex:** Memory + reinforcement pattern for adaptation
- **PettingZoo Fit:** Clone successful pursuit patterns, evolve immune response
- **Coordination:** Requires Disruptor red team for training
- **Implementation:** `agents/bio_immune_clonal_selection.py`

#### 17. **Bee Guard Behavior**
- **Source:** Moore et al. 1987 (Honeybee nest defense)
- **Type:** Defensive perimeter with alert signaling
- **Status:** üü° Pending
- **Expected:** 12% (documented low performer)
- **Why Apex:** Known low performer, test for synergy with other roles
- **PettingZoo Fit:** Defensive posture wrong for predator role (anti-pattern)
- **Coordination:** May synergize with Navigator for zone defense
- **Implementation:** Needed (low priority)

#### 18. **Noise Filtered Pursuit Variants**
- **Source:** QD Discovery + filtering
- **Type:** Signal filtering to remove observation noise
- **Status:** ‚úÖ Implemented & Tested (2 variants)
- **Performance:** 42-44% vs DDPG (struggling)
- **Why Apex:** Defensive filtering approach
- **PettingZoo Fit:** Filtering reduces aggression, wrong for predator
- **Coordination:** Standalone underperforms
- **Implementation:** `agents/qd_noise_filtered*.py`

---

### üî¥ Disruptor Role (Adversarial Testing/Attack Discovery)

#### 19. **Immune Hypermutation (Somatic)** üöÄ BREAKTHROUGH
- **Source:** Tonegawa 1983 (Antibody diversity generation)
- **Type:** Random mutation of pursuit parameters explores attack space
- **Status:** ‚úÖ Implemented & Tested (100 eps vs DDPG)
- **Performance:** 83% vs DDPG (B-tier)
- **Expected:** 35-45% ‚Üí **+38% overshoot (largest absolute!)**
- **Why Apex:** Diversity exploration accidentally discovers optimal strategies
- **PettingZoo Fit:** Random attack vector exploration effective in bounded space
- **Coordination:** May generate novel attack patterns for Immunizer training
- **Implementation:** `agents/bio_immune_hypermutation.py`

#### 20. **Red Team Probing (ATP-7-100.1)** üöÄ TIER 1
- **Source:** ATP-7-100.1 Red Team Operations (Systematic attack vectors)
- **Type:** Cycles through frontal/flanking/ambush/retreat every 5 steps
- **Status:** ‚úÖ Implemented & Tested (100 eps vs DDPG)
- **Performance:** 76% vs DDPG (C-tier)
- **Expected:** 30-40% ‚Üí **+36% overshoot**
- **Why Apex:** Systematic probing discovers prey vulnerabilities
- **PettingZoo Fit:** Attack vector cycling works in bounded tactical space
- **Coordination:** Requires Immunizer to test defenses
- **Implementation:** `agents/mil_red_team_probing.py`

#### 21. **MITRE ATT&CK Simulation**
- **Source:** MITRE ATT&CK Framework (Adversarial tactics)
- **Type:** Adversarial scenario generation
- **Status:** üü° Pending
- **Expected:** Unknown
- **Why Apex:** Systematic adversarial testing framework
- **PettingZoo Fit:** Translate cyber tactics to pursuit tactics
- **Coordination:** Requires Immunizer to test defenses
- **Implementation:** Needed

---

### üåê Infuser Role (Logistics/Resource Flow)

#### 22. **Physarum Network Optimization (Slime Mold)** üöÄ BREAKTHROUGH
- **Source:** Tero et al. 2010 (Slime mold network design)
- **Type:** Network spawning + reinforcement for adaptive paths
- **Status:** ‚úÖ Implemented & Tested (100 eps vs DDPG)
- **Performance:** 85% vs DDPG (A-tier)
- **Expected:** 50-60% ‚Üí **+25% overshoot**
- **Why Apex:** Optimal network routing with reinforcement
- **PettingZoo Fit:** Path network spawning for multi-swarm L1+ operations
- **Coordination:** Resource routing for multi-swarm coordination
- **Implementation:** `agents/bio_slime_mold_network.py`

#### 23. **Ant Trophallaxis (Food Sharing)**
- **Source:** H√∂lldobler & Wilson 1990
- **Type:** Resource distribution across agents
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 56% vs DDPG
- **Expected:** Unknown
- **Why Apex:** Distributed resource allocation
- **PettingZoo Fit:** No explicit resources in simple_tag, but info sharing applies
- **Coordination:** Resource distribution across agents
- **Implementation:** `agents/bio_ant_trophallaxis.py`

---

### üìä Analyzer Role (Assessment/Learning)

#### 24. **Meta_Analyzer (Formation Quality)** ü•á NEW CHAMPION - S-TIER
- **Source:** HFO meta-level formation scoring
- **Type:** Formation quality assessment (spread, coordination, distances)
- **Status:** ‚úÖ Implemented & Tested (100 eps vs DDPG)
- **Performance:** **93% vs DDPG (S-tier, #1!), 12.4 avg cycles (FASTEST!)**
- **Expected:** 30-45% ‚Üí **+48% overshoot**
- **Why Apex:** Meta-coordination beats individual optimization
- **PettingZoo Fit:** Formation assessment creates emergent team coordination
- **Coordination:** Wrapped with minimal pursuit fallback
- **Implementation:** `agents/hfo_meta_analyzer.py`
- **KEY INSIGHT:** First primitive to exceed 90% L0 target!

#### 25. **SRE Error Budget**
- **Source:** Google SRE Book (Service level objectives)
- **Type:** Continuous improvement feedback loop
- **Status:** üü° Pending
- **Expected:** Unknown
- **Why Apex:** Systematic learning from failure budget
- **PettingZoo Fit:** Track catch rate SLOs, adapt when budget exceeded
- **Coordination:** Continuous improvement feedback loop
- **Implementation:** Needed

#### 26. **F3EAD Analysis (Find, Fix, Finish, Exploit, Analyze, Disseminate)**
- **Source:** ATP-2-01 (Intelligence analysis)
- **Type:** Strategic learning from outcomes
- **Status:** üü° Pending
- **Expected:** Unknown
- **Why Apex:** Military intelligence cycle for pattern extraction
- **PettingZoo Fit:** Analyze episode outcomes for strategic learning
- **Coordination:** Strategic learning from outcomes
- **Implementation:** Needed

---

### üß≠ Navigator Role (Orchestration/Multi-Swarm C2)

#### 27. **Ant Task Allocation** üöÄ BREAKTHROUGH
- **Source:** Gordon 2011 (Decentralized task switching)
- **Type:** Dynamic role switching (scout‚Üístriker‚Üíherder)
- **Status:** ‚úÖ Implemented & Tested (100 eps vs DDPG)
- **Performance:** **86% vs DDPG (A-tier), 11.8 avg cycles (2nd FASTEST!)**
- **Expected:** 55-65% ‚Üí **+21% overshoot**
- **Why Apex:** Role flexibility enables adaptive coordination
- **PettingZoo Fit:** Dynamic role assignment (who chases, who blocks)
- **Coordination:** Requires supporting Shapers for execution
- **Implementation:** `agents/bio_ant_task_allocation.py`

#### 28. **QD Formation Distance (Champion)** ‚≠ê TESTED - BEST PRE-TIER1
- **Source:** HFO QD Gen 33 (MAP-Elites discovery, formation_distance=0.121)
- **Type:** Adaptive tightening parameter
- **Status:** ‚úÖ Implemented & Tested (300 eps vs random, 100 eps vs DDPG)
- **Performance:** 82.7% vs random (B-tier), **59% vs DDPG (#1 pre-Tier1!)**
- **Gap:** **-23.7% (SMALLEST DROP)** = best generalization
- **Why Apex:** QD-discovered parameter outperforms all hand-designed
- **PettingZoo Fit:** Adaptive spacing for coordinated pursuit
- **Coordination:** Combine with PotentialField (90.7%) for synergy
- **Implementation:** `tests/test_prey_simple_tag_v1_batch1.py::QDChampionTighter`

#### 29. **Mosaic Tile Reconfiguration**
- **Source:** JP-5-0 (Joint planning process)
- **Type:** L1+ multi-swarm coordination
- **Status:** üü° Pending
- **Expected:** Unknown
- **Why Apex:** Modular force reconfiguration for mosaic warfare
- **PettingZoo Fit:** Multi-swarm L1+ coordination layer
- **Coordination:** L1+ multi-swarm coordination
- **Implementation:** Needed

#### 30. **L1 Parallel Coordination**
- **Source:** HFO multi-swarm architecture
- **Type:** Multi-swarm routing and synchronization
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 49% vs DDPG (struggling)
- **Why Apex:** Multi-swarm coordination capability
- **PettingZoo Fit:** Needs supporting Shapers, standalone underperforms
- **Coordination:** Navigator orchestrates, Shapers execute
- **Implementation:** `agents/sota_l1_parallel.py`

---

## ü§ñ ROBOTIC/INDUSTRY PRIMITIVES

### üîß Bridger/Shaper Hybrids

#### 31. **Particle Filter (Monte Carlo Localization)**
- **Source:** Thrun et al. 2005 (Probabilistic Robotics)
- **Type:** Monte Carlo sampling of prey states (100 particles)
- **Status:** üü° Pending
- **Expected:** 84-87%
- **Why Apex:** Better for multi-modal distributions (prey at fork)
- **PettingZoo Fit:** Handle uncertainty in bounded space with obstacles
- **Coordination:** Enhances Observer with probabilistic tracking
- **Implementation:** Needed

#### 32. **Leader Election (Bully Algorithm)**
- **Source:** Garc√≠a-Molina 1982
- **Type:** Highest-fitness agent becomes coordinator
- **Status:** üü° Pending
- **Expected:** 86-89%
- **Why Apex:** Adaptive leadership vs fixed roles
- **PettingZoo Fit:** Dynamic coordination based on proximity/success
- **Coordination:** Agent closest to prey becomes temporary leader
- **Implementation:** Needed

#### 33. **Wall Bounce Prediction**
- **Source:** SOTA geometric
- **Type:** Predict prey wall-bounce maneuvers
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 55% vs DDPG
- **Why Apex:** Obstacle-aware prediction
- **PettingZoo Fit:** Bounded space makes wall prediction critical
- **Coordination:** Standalone mid-tier
- **Implementation:** `agents/sota_wall_bounce.py`

#### 34. **Acceleration Exploit**
- **Source:** SOTA physics
- **Type:** Exploit prey acceleration limits
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 55% vs DDPG
- **Why Apex:** Physics-based interception
- **PettingZoo Fit:** Continuous action space enables acceleration analysis
- **Coordination:** Standalone mid-tier
- **Implementation:** `agents/sota_accel_exploit.py`

---

## üìê GEOMETRIC/QD PRIMITIVES

#### 35. **QD Champion Tighter** - See Navigator #28 above

#### 36. **Dynamic Encirclement**
- **Source:** QD Experimental
- **Type:** Adaptive geometric encirclement
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 55% vs DDPG
- **Why Apex:** QD-discovered dynamic geometry
- **PettingZoo Fit:** Bounded space enables encirclement
- **Coordination:** May improve with Navigator adjustment
- **Implementation:** `agents/qd_dynamic_encircle.py`

#### 37. **QD 5-Step Linear**
- **Source:** QD variant of prediction
- **Type:** Linear extrapolation with QD tuning
- **Status:** ‚úÖ Implemented & Tested
- **Performance:** 41% vs DDPG (struggling)
- **Why Apex:** QD-tuned prediction horizon
- **PettingZoo Fit:** Failed vs stochastic DDPG evasion
- **Coordination:** Needs reactive Shapers
- **Implementation:** `agents/qd_5step_linear.py`

---

## ü™ñ MILITARY DOCTRINE PRIMITIVES

### üéØ ATP-3-60 (Targeting Doctrine)

#### 38. **Envelopment (Double Envelopment)** ‚≠ê TESTED
- **Source:** ATP-3-60 Chapter 3
- **Type:** Fixed 120¬∞ spacing encirclement (surround from multiple sides)
- **Status:** ‚úÖ Implemented & Tested (300 eps vs random, 100 eps vs DDPG)
- **Performance:** 84.3% vs random (B-tier), 58% vs DDPG (tied #2)
- **Gap:** -26.3%
- **Why Apex:** Fixed geometric doctrine exploits learned escape patterns
- **PettingZoo Fit:** 120¬∞ spacing cuts all escape routes in bounded space
- **Coordination:** Fixed geometry + adaptive tactics = synergy potential
- **Implementation:** `tests/test_prey_simple_tag_v1_batch1.py::Envelopment`

#### 39. **Blocking Positions (A4)**
- **Source:** ATP-3-60 Chapter 4
- **Type:** Cut escape routes
- **Status:** ‚úÖ Tested (legacy)
- **Performance:** 83% (A4 legacy test)
- **Why Apex:** Deny enemy freedom of maneuver
- **PettingZoo Fit:** Obstacles create natural blocking terrain
- **Coordination:** Combine with pursuit for pincer
- **Implementation:** Legacy (needs update)

#### 40. **Fire & Maneuver**
- **Source:** ATP-3-60 Chapter 5
- **Type:** 2 agents fix (pin), 1 agent flanks
- **Status:** üü° Pending
- **Expected:** 85-88%
- **Why Apex:** Prevent prey from predicting all threats
- **PettingZoo Fit:** Bounded space enables flanking maneuvers
- **Coordination:** Requires role coordination (fix vs maneuver)
- **Implementation:** Needed

### üì° ATP-3-55 (Information Collection)

#### 41. **Multi-Source Fusion**
- **Source:** ATP-3-55 Chapter 3
- **Type:** Combine visual + stigmergic blackboard signals
- **Status:** üü° Pending
- **Expected:** 85-88%
- **Why Apex:** Reduce observation noise through redundancy
- **PettingZoo Fit:** Fuse direct observation + blackboard signals
- **Coordination:** Enhances Observer layer
- **Implementation:** Needed

#### 42. **Pattern-of-Life Analysis**
- **Source:** ATP-3-55 Chapter 4
- **Type:** Model prey behavior over time (history buffer 5-10 steps)
- **Status:** üü° Pending
- **Expected:** 84-87%
- **Why Apex:** Better prediction for habitual behavior
- **PettingZoo Fit:** Extract prey movement signature over episodes
- **Coordination:** Feeds Bridger layer
- **Implementation:** Needed

#### 43. **Predictive Intelligence**
- **Source:** ATP-3-55 Chapter 5
- **Type:** Bayesian intent inference (heading toward obstacle/wall/center?)
- **Status:** üü° Pending
- **Expected:** 86-89%
- **Why Apex:** Beat linear extrapolation for intelligent prey
- **PettingZoo Fit:** Bounded space enables intent inference
- **Coordination:** Enhances Observer with intent layer
- **Implementation:** Needed

#### 44. **Denied-Area Sensing**
- **Source:** ATP-3-55 Chapter 6
- **Type:** Wall/obstacle awareness in prediction (ray-casting)
- **Status:** üü° Pending
- **Expected:** 85-88%
- **Why Apex:** Reduce prediction error near boundaries
- **PettingZoo Fit:** Obstacles and walls critical in bounded space
- **Coordination:** Enhances Observer with obstacle layer
- **Implementation:** Needed

### üìã JP-6-0 (Joint Communications)

#### 45. **Common Operational Picture (COP)**
- **Source:** JP-6-0 Chapter 2
- **Type:** Shared state across all agents (stigmergic blackboard)
- **Status:** ‚úÖ Tested (legacy L1)
- **Performance:** 87% (L1 stigmergy validated)
- **Why Apex:** Shared situational awareness
- **PettingZoo Fit:** Blackboard perfect for bounded multi-agent
- **Coordination:** Foundation for all coordination
- **Implementation:** Legacy (integrated into architecture)

#### 46. **De-Confliction**
- **Source:** JP-6-0 Chapter 3
- **Type:** Collision avoidance via priority arbitration (agent ID priority)
- **Status:** üü° Pending
- **Expected:** 86-89%
- **Why Apex:** Prevent clustering, maintain spacing
- **PettingZoo Fit:** Bounded space requires collision avoidance
- **Coordination:** Enhances all Shapers
- **Implementation:** Needed

#### 47. **Priority-Based Tasking**
- **Source:** JP-6-0 Chapter 4
- **Type:** Closest agent chases, others block escape routes
- **Status:** üü° Pending
- **Expected:** 87-90%
- **Why Apex:** Better division of labor than fixed roles
- **PettingZoo Fit:** Dynamic role assignment in 3v1
- **Coordination:** Requires distance calculation
- **Implementation:** Needed

#### 48. **Commander's Intent Propagation**
- **Source:** JP-6-0 Chapter 5
- **Type:** Mission-type orders (blackboard broadcasts "ENCIRCLE" or "CHASE")
- **Status:** üü° Pending
- **Expected:** 86-89%
- **Why Apex:** Adaptive coordination without central control
- **Coordination:** Agents adapt locally to broadcast intent
- **Implementation:** Needed

---

## üåü OTHER/CROSS-DOMAIN PRIMITIVES

### ü¶† Biological (Lion Pride)

#### 49. **Lion Silent Coordination**
- **Source:** Stander 1992 (Lions coordinate via visual cues)
- **Type:** React to other predator positions (form triangle without comms)
- **Status:** üü° Pending
- **Expected:** 84-87%
- **Why Apex:** Robust to communication failure
- **PettingZoo Fit:** Position-based coordination in observable space
- **Coordination:** Visual cues only, no explicit messaging
- **Implementation:** Needed

### üêù Biological (Bee Waggle Dance)

#### 50. **Bee Waggle Dance (Vector Communication)**
- **Source:** Von Frisch 1967
- **Type:** Encode direction/distance as signal (not absolute position)
- **Status:** üü° Pending
- **Expected:** 83-86%
- **Why Apex:** Better for partial observability
- **PettingZoo Fit:** Blackboard stores vector to prey
- **Coordination:** Relative encoding robust to position drift
- **Implementation:** Needed

---

## üî¨ SYNERGY HYPOTHESES (Multi-Primitive Combinations)

### High-Priority Combinations for MAP-Elites L1

1. **Meta_Analyzer + QD_Champion** (93% + 59%)
   - Formation assessment + adaptive spacing
   - Hypothesis: Meta-coordination with QD-tuned parameters
   - Expected: **95%+ (L0 target achieved!)**

2. **QD_Champion + Envelopment** (59% + 58%)
   - Adaptive tightening + fixed 120¬∞ geometry
   - Hypothesis: Champion varies spacing, Envelopment locks corners
   - Expected: 65-75% (synergy gain: +6-16%)

3. **Voronoi + Potential_Field** (57% + 58%)
   - Coverage partitioning + force field gradients
   - Hypothesis: Voronoi divides space, fields create traps
   - Expected: 65-70% (synergy gain: +7-12%)

4. **Raptor + Wolf + Envelopment** (54% + 53% + 58%)
   - Intercept + Arc + Fixed geometry (3-way combo)
   - Hypothesis: Raptor dives, Wolf arcs, Envelopment locks
   - Expected: 70-80% (synergy gain: +15-25%)

5. **Ant_Recruitment + Ant_Task_Allocation** (86% + 86%)
   - Signal amplification + role flexibility
   - Hypothesis: Both ant-inspired A-tier, complementary mechanisms
   - Expected: **90%+ (A-tier synergy)**

6. **L1_Parallel + [Top Shapers]** (49% + 55-59%)
   - Navigator coordination + tactical execution
   - Hypothesis: L1 orchestrates, Shapers execute in parallel
   - Expected: 60-75% (synergy gain: +10-25%)

---

## üéØ PETTINGZOO APPLICABILITY RATIONALE

### Why These Primitives Excel in PettingZoo

1. **Bounded Space** (2D continuous, walls, obstacles)
   - Geometric primitives (Voronoi, Envelopment, formations) leverage boundaries
   - Wall-bounce prediction critical for obstacle-rich environments
   - Force fields naturally bounded by space constraints

2. **No Stamina Mechanics**
   - Pursuit is pure geometry + velocity, not endurance
   - Sprint/relay strategies (African wild dog) underperform
   - Continuous acceleration possible (unlike biological limits)

3. **Observable State** (full/partial observability)
   - Visual tracking primitives (Wolf, Raptor) directly applicable
   - Stigmergic blackboard enables pheromone/signal primitives
   - Formation assessment (Meta_Analyzer) leverages full state

4. **3 Predator vs 1 Prey Configuration**
   - Multi-agent coordination critical (COP, task allocation)
   - Encirclement/envelopment natural for 3v1
   - Role diversity (Observer/Bridger/Shaper) maps to 3 agents

5. **Max 25-100 Cycles**
   - Fast convergence required (Meta_Analyzer 12.4 cycles optimal)
   - Long-term learning primitives (SRE, F3EAD) apply across episodes
   - Prediction horizon limited (5-step Kalman fails vs stochastic)

---

## üß† SWARMLORD C2 + VIRTUAL STIGMERGY CONTEXT

### Coordination Layer Architecture

All primitives wrapped with:

1. **SwarmlordC2 Commander** (Navigator orchestrator)
   - Facade pattern for user interface
   - Strategic C2 for meta-evolution
   - Tactical execution delegation to primitives
   - Alter ego to user (user = overmind, Swarmlord = strategic/tactical)

2. **Virtual Stigmergy Layer (VSL)**
   - CRDT-backed blackboard (PN-Counters, LWW-Maps, G-Sets)
   - Pheromone fields (need_help, prey_seen, etc.)
   - Lamport clocks + gossip for causal consistency
   - TTL/evaporation for freshness

3. **Multi-Layer Coordination**
   - **L0:** Individual primitive performance (current focus)
   - **L1:** Combination synergies via MAP-Elites (next phase)
   - **L1+:** Multi-swarm coordination (Navigator + Infuser)

### Why Many Primitives Perform Poorly Alone

**KEY INSIGHT:** Individual pursuit optimization (56.4% APEX mean) < Meta-coordination (84.2% Tier 1 mean)

Examples:
- **L1_Parallel (49%):** Navigator needs Shapers to orchestrate
- **Kalman variants (41-49%):** Prediction needs reactive execution
- **Sprint_Intercept (40%):** Role assignment critical, standalone fails
- **Ant_Recruitment (86%):** Signal amplification requires Observer input

**Solution:** SwarmlordC2 wraps primitives into coordinated swarms, enabling emergent synergies that individual primitives cannot achieve.

---

## üìà EXPLORE/EXPLOIT RATIO (4/6)

### Exploration (40%)

**Primitives for Exploration:**
- Ant Scout Trail Memory (explore environment)
- Immune Hypermutation (explore attack space via random mutation)
- Red Team Probing (explore attack vectors systematically)
- Particle Filter (explore multi-modal state hypotheses)
- QD variants (explore parameter space)

**Mechanisms:**
- MAP-Elites QD grid (quality-diversity optimization)
- Novelty search for diverse tactics
- Scout caste (10-20% of population)

### Exploitation (60%)

**Primitives for Exploitation:**
- Raptor Dive (exploit optimal intercept)
- Potential Field (exploit force gradients)
- Envelopment (exploit fixed geometry)
- Meta_Analyzer (exploit formation quality)
- Voronoi (exploit spatial coverage)

**Mechanisms:**
- Clonal Selection (clone successful patterns)
- Ant Recruitment (amplify successful signals)
- Leader Election (exploit best performers)

**Balance:** 40/60 ratio ensures diversity (avoid local optima) while exploiting known strong performers (convergence).

---

## üìù IMPLEMENTATION PRIORITIES

### ‚úÖ Completed (31 primitives)
- All Tier 1 meta-coordination (6 primitives, 76-93%)
- All APEX baseline (5 primitives, 53-59%)
- Selected SOTA and QD variants (20 primitives)

### üü° High Priority (Next 8 primitives)
1. Particle Filter (PERCEIVE) - 84-87% expected
2. Priority-Based Tasking (REACT) - 87-90% expected
3. Fire & Maneuver (ENGAGE) - 85-88% expected
4. Dolphin Herding (ENGAGE) - 85-88% expected
5. Leader Election (REACT) - 86-89% expected
6. Multi-Source Fusion (PERCEIVE) - 85-88% expected
7. Predictive Intelligence (PERCEIVE) - 86-89% expected
8. De-Confliction (REACT) - 86-89% expected

### üîµ Medium Priority (Fill Archive Diversity)
- Remaining biological (Wolf Visual, Lion Ambush, etc.)
- Remaining military (Pattern-of-Life, Denied-Area, etc.)
- Remaining industry (Consensus Voting, etc.)

### üü¢ Low Priority / Anti-Patterns
- Bee Guard (12% documented, defensive wrong for predator)
- Sprint Intercept (40%, no stamina in PettingZoo)
- Noise Filtered variants (42-44%, filtering reduces aggression)

---

## üîÑ NEXT STEPS

1. **Complete Easy Baseline Testing** (~11 primitives need Tier 3: 300 eps vs random)
2. **Implement High Priority 8** (fill critical OBSIDIAN role gaps)
3. **Launch MAP-Elites L1** (100+ niche archive, target 90%+ combinations)
4. **Extract Elite Principles** (for L2 abstraction)
5. **Validate 90%+ Target** (L0 passing threshold, Meta_Analyzer already achieved!)

---

## üìö REFERENCES

### Military Doctrine
- ATP-3-55: US Army Information Collection (2015)
- ATP-3-60: Targeting (2015)
- ATP-7-100.1: Red Team Operations (2021)
- JP-5-0: Joint Planning (2022)
- JP-6-0: Joint Communications System (2022)

### Biological
- H√∂lldobler & Wilson (1990): The Ants
- Mech & Boitani (2003): Wolves: Behavior, Ecology, Conservation
- Stander (1992): Cooperative Hunting in Lions
- Shifferman & Eilam (2004): Raptor Hunting Behavior
- Creel & Creel (1995): African Wild Dog Relay Hunting
- Lewis & Schroeder (2003): Dolphin Cooperative Herding
- Sharpe & Dill (1997): Orca Bubble Net Feeding
- Benoit-Bird & Au (2009): Pelagic Dolphin Herding
- Au & Hastings (2008): Dolphin Echolocation
- Von Frisch (1967): Bee Communication
- Moore et al. (1987): Honeybee Nest Defense
- Tonegawa (1983): Somatic Hypermutation
- De Castro & Von Zuben (2002): Artificial Immune Systems
- Gordon (2011): Ant Task Allocation
- Tero et al. (2010): Physarum Network Optimization

### Industry/Robotics
- Khatib (1986): Real-Time Obstacle Avoidance for Manipulators
- Welch & Bishop (1995): Introduction to the Kalman Filter
- Thrun et al. (2005): Probabilistic Robotics
- Fortune (1987): Voronoi Diagrams (Computational Geometry)
- Okabe et al. (2000): Spatial Tessellations
- Ongaro & Ousterhout (2014): Raft Consensus Algorithm
- Garc√≠a-Molina (1982): Bully Leader Election

### AI/RL Research
- Vinyals et al. (2019): AlphaStar (League Training, Nature)
- Ellis et al. (2022): SMACv2 (Perturbations, NeurIPS)
- Pugh et al. (2016): MAP-Elites (Quality-Diversity, Frontiers)
- Rubenstein et al. (2014): Kilobots (Large-N Swarms, Science)
- Werfel et al. (2014): TERMES Robots (Stigmergy, Science)

---

## üèÜ KEY ACHIEVEMENTS

- **Meta_Analyzer (93%):** First S-tier primitive, exceeds 90% L0 target vs DDPG
- **Tier 1 Breakthroughs:** 6 primitives vastly exceeded expectations (+21% to +48%)
- **QD Validation:** QD-discovered primitives outperform hand-designed (59% best pre-Tier1)
- **Meta > Individual:** Meta-coordination (84.2%) beats individual pursuit (56.4%)
- **Comprehensive Coverage:** 50 primitives across 8 OBSIDIAN roles, 4 source domains

---

**Document Status:** ‚úÖ Complete  
**Last Updated:** 2025-10-28  
**Version:** 1.0  
**Maintainer:** HFO Hive Fleet Obsidian  
**Purpose:** Consolidated research for import to other repositories

---

*This document synthesizes information from PRIMITIVE_LIBRARY_HUNT.md, üï∏‚õ∞üéØü•á_L0_GROUND_TRUTH_16_PRIMITIVES.md, prey_qd_full_primitive_library.py, test_apex_primitives_vs_ddpg.py, and other HFO sources. All primitives designed for PettingZoo MPE2 simple_tag_v3 environment with SwarmlordC2 coordination and virtual stigmergy.*
---
# üï∏Ô∏è‚õ∞Ô∏èüíé PettingZoo Apex Primitives Master List

**Date:** 2025-10-28  
**Mission:** Complete categorized inventory of all apex primitives for PettingZoo test environment  
**Focus:** No stamina, bounded space with obstacles (simple_tag 3 predators, 1 prey)  
**Coordination:** All primitives wrapped with SwarmLord C2 commander and virtual stigmergy  
**Seed:** explore/exploit 6/4 ratio

---

## üìã BLUF (Bottom Line Up Front)

**Total Primitives:** 45+ across 8 OBSIDIAN roles  
**Tested:** 16 primitives with performance data (10-91% catch rate)  
**Untested:** 29+ primitives requiring implementation and validation  
**Top Performers:** Potential Field (90.7%), QD Champion (88.3%), Envelopment (84.3%)  
**PettingZoo Environment:** simple_tag_v3, 3 predators vs 1 prey, 2 obstacles, max_cycles=25-100  
**Target Performance:** ‚â•90% catch rate through multi-primitive synergy and role coordination

**Key Insight:** Many primitives perform poorly alone (20-40%) but excel when combined through SwarmLord C2 coordination and virtual stigmergy. Multiple coordination layers enable synergistic behaviors where X=20% + Y=20% can achieve 90%+ combined performance.

---

## üéØ PERFORMANCE MATRIX (Tested Primitives)

| Tier | Primitive | Category | Role | Catch Rate | Cycles | Source | Status |
|------|-----------|----------|------|------------|--------|--------|--------|
| **S** | Potential Field | Robotic | Shaper | 90.7% | ~15 | Khatib 1986 | ‚úÖ Tested 300 eps |
| **A** | QD Formation (0.121) | Geometric | Navigator | 88.3% | ~16 | MAP-Elites Gen33 | ‚úÖ Tested 300 eps |
| **A** | L1 Parallel | Multi-role | Navigator | 88% vs random, 71% vs DDPG | ~18 | HFO Gen1 | ‚úÖ Tested 500 eps |
| **B** | Envelopment | Military | Shaper | 84.3% | ~17 | ATP-3-60 Ch3 | ‚úÖ Tested 300 eps |
| **B** | Wolf Encirclement | Biological | Shaper | 83% | ~18 | Mech & Boitani 2003 | ‚úÖ Tested 300 eps |
| **B** | Voronoi Partition | Geometric | Bridger | 83% | ~19 | Fortune 1987 | ‚úÖ Tested 300 eps |
| **B** | Kalman Filter 2D | Robotic | Bridger | 86% | ~17 | Kalman 1960 | ‚úÖ Tested standalone |
| **C** | Wall Bounce (A3) | Geometric | Shaper | 55% | ~22 | HFO QD | ‚úÖ Tested |
| **C** | Accel Exploit (A4) | Geometric | Shaper | 55% | ~22 | HFO QD | ‚úÖ Tested |
| **C** | Dynamic Encirclement | Geometric | Shaper | 55% | ~22 | HFO QD | ‚úÖ Tested |
| **C** | Raptor Dive Intercept | Biological | Observer | 54% | ~23 | Shifferman & Eilam 2004 | ‚úÖ Tested |
| **C** | QD Noise Filtered | Geometric | Immunizer | 44% | ~24 | HFO QD Exp4a | ‚úÖ Tested |
| **C** | Noise Filtered Pursuit | Robotic | Immunizer | 42% | ~24 | Research | ‚úÖ Tested |
| **C** | QD 5-Step Linear | Geometric | Bridger | 41% | ~24 | HFO QD | ‚úÖ Tested |
| **D** | Sprint Intercept | Biological | Shaper | 40% | ~25 | Creel & Creel 1995 | ‚úÖ Tested |
| **F** | Random Baseline | N/A | N/A | 10-15% | ~25 | N/A | ‚úÖ Baseline |

**Notes:**
- Catch rates vs random prey unless noted
- Lower-tier primitives often excel in combination with others
- Multi-layer coordination amplifies effectiveness significantly

---

## ü¶Å BIOLOGICAL PRIMITIVES

### Observer Role (ISR/Sensing)

#### 1. **Raptor Dive Intercept** ‚úÖ TESTED
- **Source:** Shifferman & Eilam 2004 (raptor hunting behavior)
- **Apex Rationale:** Optimal time-to-intercept calculation, closing speed geometry
- **PettingZoo Application:** Lead target based on relative velocity, works with bounded space
- **Performance:** 54% catch rate (tested 300 episodes)
- **Synergy:** Requires Navigator for multi-agent coordination
- **Coordination Layer:** Observer detects ‚Üí Bridger fuses ‚Üí Shaper executes intercept
- **Status:** Implemented

#### 2. **Wolf Scout Patrol** üî¥ UNTESTED
- **Source:** Mech & Boitani 2003 (wolf pack scouting)
- **Apex Rationale:** Wide-area reconnaissance, early prey detection
- **PettingZoo Application:** Patrol patterns in bounded space, fog-of-war sensing
- **Expected Performance:** Unknown (requires pack coordination)
- **Synergy:** Requires Navigator for pack coordination, Bridger for signal fusion
- **Coordination Layer:** Scout observes ‚Üí broadcasts via stigmergy ‚Üí pack responds
- **Status:** Pending implementation

#### 3. **Ant Pheromone Trail** üî¥ UNTESTED
- **Source:** H√∂lldobler & Wilson 1990 (ant colony optimization)
- **Apex Rationale:** Stigmergic path marking, indirect coordination
- **PettingZoo Application:** Virtual trail following in pursuit paths, obstacle navigation
- **Expected Performance:** Unknown (needs stigmergy integration)
- **Synergy:** Requires Bridger for signal integration and decay management
- **Coordination Layer:** Observer marks trail ‚Üí Bridger maintains intensity ‚Üí others follow
- **Status:** Pending implementation

#### 4. **Dolphin Echolocation** üî¥ UNTESTED
- **Source:** Au & Hastings 2008 (dolphin sensing)
- **Apex Rationale:** Multi-bounce environment sensing, wall reflection detection
- **PettingZoo Application:** Predict prey wall-bounce maneuvers early
- **Expected Performance:** 83-86% (estimated)
- **Synergy:** Enhanced with Bridger fusion for reflection analysis
- **Coordination Layer:** Observer detects reflections ‚Üí Bridger predicts trajectory ‚Üí Shaper positions
- **Status:** Pending implementation

#### 5. **Wolf Visual Tracking** üî¥ UNTESTED
- **Source:** Mech & Boitani 2003 (sustained visual pursuit)
- **Apex Rationale:** Noise filtering through sustained lock, high-alpha smoothing
- **PettingZoo Application:** Filter observation noise while staying responsive
- **Expected Performance:** 85-88% (estimated)
- **Synergy:** Pairs with Kalman filter or particle filter for optimal estimation
- **Coordination Layer:** Observer locks target ‚Üí Bridger smooths ‚Üí Shaper maintains pursuit
- **Status:** Pending implementation

### Shaper Role (Execution/Maneuver)

#### 6. **Wolf Encirclement** ‚úÖ TESTED
- **Source:** Mech & Boitani 2003 (wolf pack hunting)
- **Apex Rationale:** Wide arc formation tightening gradually to prevent escape
- **PettingZoo Application:** Start wide (0.5 distance), converge to 0.15 over time
- **Performance:** 83% catch rate (B-TIER, tested 300 episodes)
- **Synergy:** May improve with Navigator tightening control
- **Coordination Layer:** Navigator assigns positions ‚Üí Shapers execute arc ‚Üí converge on signal
- **Status:** Implemented

#### 7. **Sprint Intercept** ‚úÖ TESTED
- **Source:** Creel & Creel 1995 (African wild dog relay hunting)
- **Apex Rationale:** High-speed burst pursuit with role rotation
- **PettingZoo Application:** Sprint-block rotation in bounded space
- **Performance:** 40% catch rate (tested)
- **Synergy:** Requires Navigator role assignment (who sprints, who blocks)
- **Coordination Layer:** Navigator assigns sprint/block ‚Üí Shapers execute ‚Üí rotate on fatigue
- **Status:** Implemented (underperforms alone, needs coordination)

#### 8. **Dolphin Strand Feeding** üî¥ UNTESTED
- **Source:** Lewis & Schroeder 2003 (cooperative herding)
- **Apex Rationale:** Multi-stage herding to boundary, coordinated push
- **PettingZoo Application:** Herd prey toward obstacles/walls, trap against boundary
- **Expected Performance:** Unknown
- **Synergy:** Requires Bridger spatial coordination for multi-phase execution
- **Coordination Layer:** Bridger plans phases ‚Üí Shapers execute herding ‚Üí coordinated push
- **Status:** Pending implementation

#### 9. **Orca Wave Washing** üî¥ UNTESTED
- **Source:** Pitman & Durban 2012 (orca seal hunting)
- **Apex Rationale:** Coordinated boundary push, wave generation
- **PettingZoo Application:** Use walls/obstacles for coordinated compression
- **Expected Performance:** Unknown (coordination-dependent)
- **Synergy:** Requires Navigator for synchronized timing
- **Coordination Layer:** Navigator times wave ‚Üí Shapers synchronize push ‚Üí compress prey space
- **Status:** Pending implementation

#### 10. **Orca Carousel Feeding** üî¥ UNTESTED
- **Source:** Simil√§ & Ugarte 1993 (herring ball creation)
- **Apex Rationale:** Circular confinement through rotation, prey disorientation
- **PettingZoo Application:** Rotating formation creates virtual cage in bounded space
- **Expected Performance:** Unknown (high coordination required)
- **Synergy:** Navigator role for circular orchestration
- **Coordination Layer:** Navigator maintains formation ‚Üí Shapers rotate ‚Üí tighten radius
- **Status:** Pending implementation

#### 11. **Lion Ambush** üî¥ UNTESTED
- **Source:** Stander 1992 (lion pride hunting)
- **Apex Rationale:** Patience-based positioning, attack when prey enters kill zone
- **PettingZoo Application:** Position ahead of predicted path, wait for optimal range (<0.2)
- **Expected Performance:** Unknown (prediction-dependent)
- **Synergy:** Requires Observer prediction and Bridger timing coordination
- **Coordination Layer:** Observer predicts path ‚Üí Bridger assigns positions ‚Üí Shapers wait ‚Üí attack on signal
- **Status:** Pending implementation

### Immunizer Role (Defense/Noise Filtering)

#### 12. **Bee Guard Behavior** üî¥ SKIP
- **Source:** Moore et al. 1987 (honeybee nest defense)
- **Apex Rationale:** Defensive positioning and threat response
- **PettingZoo Application:** Not applicable (predator-focused environment)
- **Performance:** 12% documented effectiveness (too low)
- **Synergy:** N/A
- **Coordination Layer:** N/A
- **Status:** Excluded (proven ineffective, wrong domain)

#### 13. **Clonal Selection** üî¥ UNTESTED
- **Source:** De Castro & Von Zuben 2002 (artificial immune system)
- **Apex Rationale:** Clone successful patterns, discard failures, adaptive learning
- **PettingZoo Application:** Online learning from successful pursuits
- **Expected Performance:** 45-55% (estimated, learning over time)
- **Synergy:** Requires Disruptor red team for training diversity
- **Coordination Layer:** Analyzer scores outcomes ‚Üí Immunizer clones winners ‚Üí Disruptor tests
- **Status:** Pending implementation

### Disruptor Role (Red Team/Adversarial)

#### 14. **Somatic Hypermutation** üî¥ UNTESTED
- **Source:** Tonegawa 1983 (antibody diversity generation)
- **Apex Rationale:** Random mutation of pursuit parameters for diversity
- **PettingZoo Application:** Generate novel attack patterns, explore parameter space
- **Expected Performance:** 35-45% (diversity not effectiveness)
- **Synergy:** Generates diverse patterns for Immunizer training
- **Coordination Layer:** Disruptor mutates ‚Üí Analyzer scores ‚Üí Immunizer selects best
- **Status:** Pending implementation

#### 15. **Red Team Probing** üî¥ UNTESTED
- **Source:** ATP-7-100.1 (Red Team Operations)
- **Apex Rationale:** Adversarial parameter testing, weakness discovery
- **PettingZoo Application:** Probe prey defense patterns, find exploits
- **Expected Performance:** 30-40% (probing not optimized pursuit)
- **Synergy:** Feeds discoveries to Immunizer for hardening
- **Coordination Layer:** Disruptor probes ‚Üí Analyzer identifies weaknesses ‚Üí Shapers exploit
- **Status:** Pending implementation

#### 16. **MITRE ATT&CK Simulation** üî¥ UNTESTED
- **Source:** MITRE ATT&CK Framework (adversarial tactics)
- **Apex Rationale:** Structured attack library, systematic weakness testing
- **PettingZoo Application:** Systematic prey evasion pattern testing
- **Expected Performance:** Unknown (structured testing)
- **Synergy:** Requires Immunizer to test defenses
- **Coordination Layer:** Disruptor executes attack patterns ‚Üí Immunizer evaluates ‚Üí harden
- **Status:** Pending implementation

### Infuser Role (Logistics/Resources)

#### 17. **Ant Trophallaxis** üî¥ UNTESTED
- **Source:** H√∂lldobler & Wilson 1990 (food sharing)
- **Apex Rationale:** Resource redistribution, help struggling agents
- **PettingZoo Application:** Redistribute computational resources, assist slower agents
- **Expected Performance:** 45-55% (coordination boost)
- **Synergy:** Requires resource distribution across agents
- **Coordination Layer:** Analyzer identifies struggling agent ‚Üí Infuser redistributes ‚Üí efficiency improves
- **Status:** Pending implementation

#### 18. **Physarum Network Optimization** üî¥ UNTESTED
- **Source:** Tero et al. 2010 (slime mold network design)
- **Apex Rationale:** Adaptive path routing, flow optimization
- **PettingZoo Application:** Optimal path network for multi-swarm operations (L1+)
- **Expected Performance:** 50-60% (routing efficiency)
- **Synergy:** Resource routing for multi-swarm L1+ operations
- **Coordination Layer:** Infuser optimizes paths ‚Üí Navigators route swarms ‚Üí efficiency maximized
- **Status:** Pending implementation

---

## ü§ñ ROBOTIC/INDUSTRY PRIMITIVES

### Bridger Role (Sensor Fusion/C2)

#### 19. **Kalman Filter 2D** ‚úÖ TESTED
- **Source:** Kalman 1960 (optimal estimation)
- **Apex Rationale:** Optimal state estimation with uncertainty quantification
- **PettingZoo Application:** Prey position/velocity prediction with noise filtering
- **Performance:** 86% catch rate (standalone)
- **Synergy:** May improve with Observer sensor fusion
- **Coordination Layer:** Observer provides measurements ‚Üí Bridger fuses ‚Üí Shaper uses prediction
- **Status:** Implemented

#### 20. **Particle Filter** üî¥ UNTESTED
- **Source:** Thrun et al. 2005 (probabilistic robotics)
- **Apex Rationale:** Monte Carlo sampling for multi-modal distributions
- **PettingZoo Application:** Handle prey at decision points (forks), uncertainty modeling
- **Expected Performance:** 84-87% (estimated)
- **Synergy:** Better for complex environments with ambiguity
- **Coordination Layer:** Observer samples ‚Üí Bridger resamples by likelihood ‚Üí Shaper acts on best
- **Status:** Pending implementation

#### 21. **Consensus Voting** üî¥ UNTESTED
- **Source:** Raft (Ongaro & Ousterhout 2014)
- **Apex Rationale:** Majority vote on prey position, fault tolerance
- **PettingZoo Application:** Robust to sensor noise/failures through voting
- **Expected Performance:** Unknown (fault-tolerance dependent)
- **Synergy:** Requires multiple Observer inputs
- **Coordination Layer:** Observers vote ‚Üí Bridger computes median ‚Üí outliers filtered
- **Status:** Pending implementation

#### 22. **Leader Election** üî¥ UNTESTED
- **Source:** Bully Algorithm (Garc√≠a-Molina 1982)
- **Apex Rationale:** Highest-fitness agent becomes coordinator
- **PettingZoo Application:** Dynamic leadership based on proximity/fitness
- **Expected Performance:** 86-89% (estimated)
- **Synergy:** Adaptive leadership vs fixed roles
- **Coordination Layer:** Bridger elects leader ‚Üí leader coordinates ‚Üí others follow
- **Status:** Pending implementation

### Shaper Role (Execution)

#### 23. **Potential Field** ‚úÖ TESTED
- **Source:** Khatib 1986 (real-time obstacle avoidance)
- **Apex Rationale:** Emergent coordination through force fields, smooth paths
- **PettingZoo Application:** Prey=attractor, obstacles=repellers, agents=weak repellers
- **Performance:** 90.7% catch rate (S-TIER, tested 300 episodes)
- **Synergy:** Standalone emergent coordination
- **Coordination Layer:** Shaper calculates forces ‚Üí moves along gradient ‚Üí natural coordination
- **Status:** Implemented (top performer)

---

## üìê GEOMETRIC/QD PRIMITIVES

### Navigator Role (Formation/Coordination)

#### 24. **QD Formation Distance (0.121)** ‚úÖ TESTED
- **Source:** HFO QD Gen 33 (MAP-Elites discovery)
- **Apex Rationale:** Optimal formation spacing discovered through evolution
- **PettingZoo Application:** Maintain precise inter-agent distance for coordination
- **Performance:** 88.3% catch rate (QD Champion)
- **Synergy:** Combine with PotentialField (90.7%) for potential 95%+ synergy
- **Coordination Layer:** Navigator maintains formation ‚Üí Shapers execute ‚Üí optimal spacing
- **Status:** Implemented

#### 25. **Voronoi Partition** ‚úÖ TESTED
- **Source:** Fortune 1987 (computational geometry)
- **Apex Rationale:** Dynamic spatial ownership, coverage optimization
- **PettingZoo Application:** Territory assignment prevents overlap, ensures coverage
- **Performance:** 83% catch rate (tested standalone)
- **Synergy:** Requires Navigator for territory assignment updates
- **Coordination Layer:** Bridger partitions space ‚Üí Navigator assigns ‚Üí Shapers cover zones
- **Status:** Implemented

#### 26. **Wall Bounce (A3)** ‚úÖ TESTED
- **Source:** HFO QD Discovery
- **Apex Rationale:** Exploit boundary reflections, wall-based tactics
- **PettingZoo Application:** Use walls for intercept prediction and positioning
- **Performance:** 55% catch rate (C-TIER)
- **Synergy:** Pairs with boundary-aware primitives
- **Coordination Layer:** Observer predicts bounce ‚Üí Shaper positions at reflection point
- **Status:** Implemented

#### 27. **Accel Exploit (A4)** ‚úÖ TESTED
- **Source:** HFO QD Discovery
- **Apex Rationale:** Exploit acceleration dynamics, speed variation
- **PettingZoo Application:** Variable speed pursuit in bounded space
- **Performance:** 55% catch rate (C-TIER)
- **Synergy:** Timing coordination with other agents
- **Coordination Layer:** Navigator times acceleration ‚Üí Shapers synchronize ‚Üí burst pursuit
- **Status:** Implemented

#### 28. **Dynamic Encirclement** ‚úÖ TESTED
- **Source:** HFO QD Discovery
- **Apex Rationale:** Adaptive encirclement based on prey behavior
- **PettingZoo Application:** Real-time formation adjustment in response to prey
- **Performance:** 55% catch rate (C-TIER)
- **Synergy:** Requires Navigator for dynamic formation updates
- **Coordination Layer:** Observer tracks prey ‚Üí Navigator adjusts formation ‚Üí Shapers reposition
- **Status:** Implemented

#### 29. **Noise Filtered (Exp4a)** ‚úÖ TESTED
- **Source:** HFO QD Experiment 4a
- **Apex Rationale:** Noise reduction in observations, cleaner signals
- **PettingZoo Application:** Filter sensor noise for better predictions
- **Performance:** 44% catch rate (C-TIER)
- **Synergy:** Pairs with Kalman/Particle filters
- **Coordination Layer:** Observer filters ‚Üí Bridger fuses ‚Üí cleaner pursuit
- **Status:** Implemented

---

## ‚öîÔ∏è MILITARY DOCTRINE PRIMITIVES

### Shaper Role (Tactics/Maneuver)

#### 30. **Envelopment (ATP-3-60)** ‚úÖ TESTED
- **Source:** ATP-3-60 Chapter 3 (targeting doctrine)
- **Apex Rationale:** Surround from multiple sides simultaneously, cut escape routes
- **PettingZoo Application:** 3 agents form 120¬∞ spacing around prey (triangle)
- **Performance:** 84.3% catch rate (B-TIER, tested 300 episodes)
- **Synergy:** Fixed geometry, may improve with dynamic Navigator adjustment
- **Coordination Layer:** Navigator assigns sectors ‚Üí Shapers execute envelopment ‚Üí maintain spacing
- **Status:** Implemented

#### 31. **Fire & Maneuver** üî¥ UNTESTED
- **Source:** ATP-3-60 Chapter 5
- **Apex Rationale:** One team fixes (pins), another maneuvers (flanks)
- **PettingZoo Application:** 2 agents chase directly, 1 agent wide flank
- **Expected Performance:** Unknown (role diversity required)
- **Synergy:** Requires role differentiation (fixer vs flanker)
- **Coordination Layer:** Navigator assigns roles ‚Üí fixers pin ‚Üí flanker maneuvers
- **Status:** Pending implementation

#### 32. **Blocking Positions** üî¥ UNTESTED
- **Source:** ATP-3-60 Chapter 4
- **Apex Rationale:** Cut escape routes, position ahead of prey path
- **PettingZoo Application:** Position at predicted escape points
- **Expected Performance:** 83% (estimated from similar A4)
- **Synergy:** Requires Observer prediction of escape routes
- **Coordination Layer:** Observer predicts escapes ‚Üí Shapers block ‚Üí pursuit succeeds
- **Status:** Pending implementation (similar to A4)

### Observer Role (ISR/Intelligence)

#### 33. **Multi-Source Fusion** üî¥ UNTESTED
- **Source:** ATP-3-55 Chapter 3 (information collection)
- **Apex Rationale:** Combine visual + communication signals, reduce noise
- **PettingZoo Application:** Fuse direct observation + stigmergic blackboard signals
- **Expected Performance:** 85-88% (estimated)
- **Synergy:** Requires stigmergy integration
- **Coordination Layer:** Multiple Observers ‚Üí Bridger fuses ‚Üí reduced uncertainty
- **Status:** Pending implementation

#### 34. **Pattern-of-Life Analysis** üî¥ UNTESTED
- **Source:** ATP-3-55 Chapter 4
- **Apex Rationale:** Model prey behavior over time, extract movement signature
- **PettingZoo Application:** History buffer (5-10 steps), predict habitual behavior
- **Expected Performance:** 84-87% (estimated)
- **Synergy:** Pairs with predictive algorithms
- **Coordination Layer:** Observer tracks history ‚Üí Analyzer extracts patterns ‚Üí Bridger predicts
- **Status:** Pending implementation

#### 35. **Predictive Intelligence** üî¥ UNTESTED
- **Source:** ATP-3-55 Chapter 5
- **Apex Rationale:** Anticipate intent, not just velocity (Bayesian inference)
- **PettingZoo Application:** Infer prey goals (heading to center, wall, etc.)
- **Expected Performance:** 86-89% (estimated)
- **Synergy:** Better than linear extrapolation for intelligent prey
- **Coordination Layer:** Observer infers intent ‚Üí Bridger plans ‚Üí Shaper positions ahead
- **Status:** Pending implementation

#### 36. **Denied-Area Sensing** üî¥ UNTESTED
- **Source:** ATP-3-55 Chapter 6
- **Apex Rationale:** Wall/obstacle awareness in prediction
- **PettingZoo Application:** Ray-casting to walls, penalize predictions into obstacles
- **Expected Performance:** 85-88% (estimated)
- **Synergy:** Reduces error near boundaries
- **Coordination Layer:** Observer ray-casts ‚Üí Bridger filters invalid ‚Üí better prediction
- **Status:** Pending implementation

### Bridger Role (C2/Coordination)

#### 37. **Common Operational Picture** ‚úÖ TESTED
- **Source:** JP-6-0 Chapter 2 (joint communications)
- **Apex Rationale:** Shared state across all agents, situational awareness
- **PettingZoo Application:** Stigmergic blackboard for shared state
- **Performance:** 87% (L1 baseline uses this)
- **Synergy:** Foundation for all coordination
- **Coordination Layer:** Observers update ‚Üí blackboard maintains ‚Üí all agents read
- **Status:** Implemented (stigmergy)

#### 38. **De-Confliction** üî¥ UNTESTED
- **Source:** JP-6-0 Chapter 3
- **Apex Rationale:** Collision avoidance via priority arbitration
- **PettingZoo Application:** Agent ID priority, lower ID yields to prevent clustering
- **Expected Performance:** 86-89% (estimated)
- **Synergy:** Maintains spacing, prevents overlap
- **Coordination Layer:** Bridger assigns priority ‚Üí agents check before moving ‚Üí spacing maintained
- **Status:** Pending implementation

#### 39. **Priority-Based Tasking** üî¥ UNTESTED
- **Source:** JP-6-0 Chapter 4
- **Apex Rationale:** Dynamic role assignment (closest chases, others block)
- **PettingZoo Application:** Real-time role switching based on position
- **Expected Performance:** 87-90% (estimated)
- **Synergy:** Better division of labor than fixed roles
- **Coordination Layer:** Bridger calculates distances ‚Üí assigns roles ‚Üí Shapers execute
- **Status:** Pending implementation

#### 40. **Commander's Intent Propagation** üî¥ UNTESTED
- **Source:** JP-6-0 Chapter 5
- **Apex Rationale:** Mission-type orders (goal not method), adaptive execution
- **PettingZoo Application:** Broadcast "ENCIRCLE" or "CHASE" mode, agents adapt locally
- **Expected Performance:** 86-89% (estimated)
- **Synergy:** Adaptive coordination without central control
- **Coordination Layer:** Navigator broadcasts intent ‚Üí agents interpret locally ‚Üí emergent coordination
- **Status:** Pending implementation

### Navigator Role (Strategic C2)

#### 41. **Mosaic Tile Reconfiguration** üî¥ UNTESTED
- **Source:** JP-5-0 (joint planning process), Mosaic Warfare
- **Apex Rationale:** Dynamic role reassignment, adaptive force composition
- **PettingZoo Application:** L1+ multi-swarm coordination, role switching
- **Expected Performance:** Unknown (L1+ operation)
- **Synergy:** Enables complex multi-layer strategies
- **Coordination Layer:** Navigator reconfigures ‚Üí roles reassign ‚Üí swarms adapt
- **Status:** Pending implementation

### Disruptor Role (Red Team)

#### 42. **MITRE ATT&CK Framework** üî¥ UNTESTED
- **Source:** MITRE ATT&CK (adversarial tactics)
- **Apex Rationale:** Structured attack patterns, systematic testing
- **PettingZoo Application:** Test prey evasion systematically
- **Expected Performance:** Unknown (testing framework)
- **Synergy:** Requires Immunizer to test defenses
- **Coordination Layer:** Disruptor executes tactics ‚Üí Analyzer scores ‚Üí Immunizer hardens
- **Status:** Pending implementation

---

## üî¨ ANALYZER/META PRIMITIVES

### Analyzer Role (Assessment/Learning)

#### 43. **SRE Error Budget** üî¥ SKIP
- **Source:** Google SRE Book (service level objectives)
- **Apex Rationale:** Continuous improvement feedback loop
- **PettingZoo Application:** Meta-level analysis, not pursuit primitive
- **Expected Performance:** N/A (wrong abstraction layer)
- **Synergy:** N/A
- **Coordination Layer:** N/A
- **Status:** Excluded (meta-level, not primitive)

#### 44. **F3EAD Analysis** üî¥ SKIP
- **Source:** ATP-2-01 (intelligence analysis)
- **Apex Rationale:** Strategic learning from outcomes
- **PettingZoo Application:** Campaign-level, not individual pursuit
- **Expected Performance:** N/A (wrong abstraction layer)
- **Synergy:** N/A
- **Coordination Layer:** N/A
- **Status:** Excluded (campaign-level workflow)

#### 45. **Meta Analyzer** üî¥ UNTESTED
- **Source:** HFO HIVE loop (Yield/Assess step)
- **Apex Rationale:** Score outcomes (catch rate, cycles, formation quality)
- **PettingZoo Application:** Online performance assessment during episodes
- **Expected Performance:** N/A (scoring not pursuit)
- **Synergy:** Feeds all other roles for improvement
- **Coordination Layer:** All roles report ‚Üí Analyzer scores ‚Üí adjustments propagate
- **Status:** Pending implementation

---

## üß¨ OTHER/HYBRID PRIMITIVES

### Multi-Role

#### 46. **L1 Parallel** ‚úÖ TESTED
- **Source:** HFO Gen1 (hierarchical coordination)
- **Apex Rationale:** Multi-primitive combination with SwarmLord coordination
- **PettingZoo Application:** Parallel 3-predator coordination with role specialization
- **Performance:** 88% vs random, 71% vs DDPG pretrained
- **Synergy:** Foundation for combining multiple primitives
- **Coordination Layer:** Navigator orchestrates ‚Üí roles specialize ‚Üí emergent coordination
- **Status:** Implemented (hierarchical system)

#### 47. **Ant Recruitment** üî¥ UNTESTED
- **Source:** H√∂lldobler & Wilson 1990 (signal amplification)
- **Apex Rationale:** Pheromone-like signal amplification, positive feedback
- **PettingZoo Application:** If 1 predator detects, all converge via signal amplification
- **Expected Performance:** 50-60% (coordination boost)
- **Synergy:** Requires Bridger for signal integration
- **Coordination Layer:** Observer detects ‚Üí stigmergy amplifies ‚Üí Bridger broadcasts ‚Üí all converge
- **Status:** Pending implementation

#### 48. **Ant Task Allocation** üî¥ UNTESTED
- **Source:** Gordon 2011 (decentralized task switching)
- **Apex Rationale:** Dynamic role switching without central control
- **PettingZoo Application:** Agents switch roles (scout‚Üístriker‚Üíherder) based on local info
- **Expected Performance:** 55-65% (role flexibility)
- **Synergy:** Navigator for role assignment coordination
- **Coordination Layer:** Agents assess locally ‚Üí switch roles ‚Üí stigmergy coordinates
- **Status:** Pending implementation

#### 49. **Wolf Alpha Signaling** üî¥ UNTESTED
- **Source:** Mech & Boitani 2003 (pack leadership)
- **Apex Rationale:** Lead agent signals maneuver, others follow with delay
- **PettingZoo Application:** Closest agent = alpha, broadcasts next position, others form on alpha
- **Expected Performance:** 86-89% (estimated)
- **Synergy:** Tight formation vs independent action
- **Coordination Layer:** Bridger elects alpha ‚Üí alpha signals ‚Üí others follow
- **Status:** Pending implementation

#### 50. **Bee Waggle Dance** üî¥ UNTESTED
- **Source:** Von Frisch 1967 (communication protocol)
- **Apex Rationale:** Encode direction/distance as vector signal
- **PettingZoo Application:** Stigmergy stores vector to prey, not absolute position
- **Expected Performance:** Unknown (partial observability benefit)
- **Synergy:** Better for limited communication bandwidth
- **Coordination Layer:** Observer encodes vector ‚Üí stigmergy broadcasts ‚Üí agents decode
- **Status:** Pending implementation

---

## üéØ OBSIDIAN ROLE COVERAGE ANALYSIS

| Role | Implemented | Pending | Total | Coverage |
|------|-------------|---------|-------|----------|
| **Observer** | 1 | 8 | 9 | 11% |
| **Bridger** | 4 | 7 | 11 | 36% |
| **Shaper** | 10 | 5 | 15 | 67% |
| **Immunizer** | 2 | 1 | 3 | 67% |
| **Disruptor** | 0 | 3 | 3 | 0% ‚ö†Ô∏è |
| **Infuser** | 0 | 2 | 2 | 0% ‚ö†Ô∏è |
| **Analyzer** | 0 | 1 | 1 | 0% ‚ö†Ô∏è |
| **Navigator** | 3 | 3 | 6 | 50% |

**Critical Gaps:** Disruptor, Infuser, Analyzer have zero implementations

---

## üîÑ COORDINATION LAYER PATTERNS

### SwarmLord C2 Commander
- **Function:** Tactical orchestration across all 8 OBSIDIAN roles
- **Application:** Mixture-of-Experts manager, sequential at L0, parallel at L1+
- **PettingZoo Integration:** Coordinates role assignment, timing, formation
- **Key Insight:** Many low-performing primitives (20-40%) excel under SwarmLord coordination

### Virtual Stigmergy
- **Function:** Indirect coordination through shared environment
- **Application:** Blackboard for asynchronous handoffs between roles
- **PettingZoo Integration:** 
  - Observer marks detections
  - Bridger updates predictions
  - Shaper reads and executes
  - Analyzer scores and updates
- **TTL Management:** Time-to-live ensures fresh information
- **Event Format:** `{"role": "observer", "event": "detect", "data": {...}, "ttl": 3600, "next_role": "bridger"}`

### Multi-Layer Synergy Examples

**Example 1: Raptor + Kalman + Potential Field**
- Observer (Raptor Dive): Time-to-intercept calculation (54%)
- Bridger (Kalman): Smooth prediction (86%)
- Shaper (Potential Field): Execute pursuit (90.7%)
- **Expected Combined:** 95%+ through role specialization

**Example 2: Wolf Pack + Voronoi + QD Formation**
- Shaper (Wolf Encirclement): Arc formation (83%)
- Bridger (Voronoi): Territory assignment (83%)
- Navigator (QD Formation): Optimal spacing (88.3%)
- **Expected Combined:** 92%+ through spatial optimization

**Example 3: Multi-Source Fusion + Priority Tasking + Envelopment**
- Observer (Multi-Source): Fused detection (est. 85-88%)
- Bridger (Priority Tasking): Role assignment (est. 87-90%)
- Shaper (Envelopment): Execute surround (84.3%)
- **Expected Combined:** 93%+ through coordinated execution

---

## üìä IMPLEMENTATION PRIORITY MATRIX

### Tier 1: Critical Role Gaps (MUST IMPLEMENT)
1. **Immune Hypermutation** (Disruptor) - 3h - Fills 0-coverage role
2. **Red Team Probing** (Disruptor) - 2h - Fills 0-coverage role
3. **Ant Trophallaxis** (Infuser) - 2h - Fills 0-coverage role
4. **Slime Mold Network** (Infuser) - 3h - Fills 0-coverage role
5. **Meta Analyzer** (Analyzer) - 2h - Fills 0-coverage role

**Total Time:** 12 hours (~1.5 days)

### Tier 2: High-Value Observer Primitives (SHOULD IMPLEMENT)
6. **Multi-Source Fusion** (Observer) - 3h - Core ISR capability
7. **Predictive Intelligence** (Observer) - 3h - Intent-based prediction
8. **Wolf Visual Tracking** (Observer) - 2h - Noise filtering
9. **Dolphin Echolocation** (Observer) - 3h - Boundary awareness

**Total Time:** 11 hours (~1.5 days)

### Tier 3: Coordination Enhancers (NICE TO HAVE)
10. **Priority-Based Tasking** (Bridger) - 3h - Dynamic roles
11. **Ant Task Allocation** (Navigator) - 3h - Decentralized C2
12. **Wolf Alpha Signaling** (Bridger) - 2h - Pack coordination
13. **Fire & Maneuver** (Shaper) - 2h - Tactical diversity

**Total Time:** 10 hours (~1.5 days)

### Tier 4: Synergy Maximizers (OPTIMIZE)
14. **Ant Recruitment** (Bridger) - 2h - Signal amplification
15. **Orca Wave Washing** (Shaper) - 3h - Boundary tactics
16. **Dolphin Strand Feeding** (Shaper) - 3h - Multi-phase herding
17. **Mosaic Tile Reconfig** (Navigator) - 3h - L1+ coordination

**Total Time:** 11 hours (~1.5 days)

**Total Implementation Effort:** 44 hours (~5-6 days intensive)

---

## üéØ PETTINGZOO APPLICABILITY SUMMARY

### Why These Primitives Work for PettingZoo simple_tag

**Environment Constraints:**
- No stamina mechanics (unlimited energy)
- Bounded space with obstacles (2 obstacles, walls)
- 3 predators vs 1 prey
- Partial observability (limited vision range)
- Max cycles: 25-100 (time pressure)

**Primitive Advantages:**
1. **Bounded Space Exploitation:**
   - Wall Bounce, Orca Wave Washing, Dolphin Strand Feeding
   - Envelopment, Blocking Positions, Lion Ambush
   - Denied-Area Sensing, Boundary-aware prediction

2. **No Stamina = Persistence Tactics:**
   - Wolf Encirclement (gradual tightening)
   - Sprint Intercept (no fatigue penalty)
   - Sustained pursuit (Visual Tracking, Raptor Dive)

3. **Multi-Agent Coordination:**
   - SwarmLord C2 enables role specialization
   - Virtual stigmergy for asynchronous coordination
   - Formation primitives (QD, Voronoi, Envelopment)

4. **Obstacle Navigation:**
   - Potential Field (automatic repulsion)
   - Slime Mold Network (path optimization)
   - Ray-casting primitives (Denied-Area Sensing)

5. **Partial Observability:**
   - Kalman/Particle filters (state estimation)
   - Multi-Source Fusion (redundancy)
   - Stigmergy (shared state beyond vision)

### Why Lone Primitives Underperform

**Single-Layer Limitations:**
- Raptor Dive (54%): Good detection, needs execution coordination
- Sprint Intercept (40%): Good burst, needs blocking support
- Noise Filtered (44%): Clean signals, needs action planning

**Multi-Layer Solution:**
- Combine Observer + Bridger + Shaper roles
- SwarmLord orchestrates handoffs
- Stigmergy maintains shared state
- Result: 20% + 20% + 20% ‚Üí 90%+ through synergy

---

## üåä EXPLORE/EXPLOIT RATIO: 6/4 SEED

**Exploration (60%):**
- Test untested primitives (29+ pending)
- Discover new synergies through MAP-Elites
- Probe role combinations (Observer+Bridger+Shaper triplets)
- QD breeding for behavioral diversity
- Red Team adversarial discovery (Disruptor role)

**Exploitation (40%):**
- Optimize top performers (Potential Field 90.7%, QD Formation 88.3%)
- Refine parameter tuning (formation distance, repulsion threshold)
- Scale proven combinations (L1 Parallel framework)
- Harden with Immunizer/Analyzer feedback
- Production deployment of validated strategies

**Rationale:**
- PettingZoo = test environment (favor exploration)
- Many untested primitives (high discovery potential)
- Synergy space largely unexplored (combination testing)
- SwarmLord C2 enables safe exploration (controlled testing)
- 6/4 balances discovery with validation

---

## üìö COMPLETE PRIMITIVE INDEX

**By Category:**
- **Biological:** 16 primitives (wolves, orcas, dolphins, ants, bees, raptors, lions, immune system)
- **Robotic/Industry:** 8 primitives (Kalman, Particle, Potential Field, Consensus, Leader Election)
- **Geometric/QD:** 9 primitives (formations, partitions, QD discoveries)
- **Military:** 12 primitives (ATP-3-60, ATP-3-55, JP-6-0, Red Team)
- **Hybrid/Other:** 5 primitives (L1 Parallel, Meta Analyzer, multi-role)

**By Status:**
- **Tested:** 16 primitives (performance data available)
- **Pending:** 29 primitives (implementation required)
- **Excluded:** 5 primitives (wrong abstraction or proven ineffective)

**By Performance Tier (Tested Only):**
- **S-Tier (85%+):** 1 primitive (Potential Field 90.7%)
- **A-Tier (85-90%):** 3 primitives (QD Formation 88.3%, L1 Parallel 88%, Kalman 86%)
- **B-Tier (80-85%):** 3 primitives (Envelopment 84.3%, Wolf 83%, Voronoi 83%)
- **C-Tier (40-60%):** 7 primitives (Wall Bounce 55%, Raptor 54%, etc.)
- **D-Tier (<40%):** 1 primitive (Sprint 40%)
- **F-Tier (Baseline):** 1 primitive (Random 10-15%)

---

## üîÆ NEXT STEPS

1. **Fill Critical Gaps:** Implement Disruptor, Infuser, Analyzer roles (12 hours)
2. **Enhance Observers:** Add multi-source fusion and predictive intel (11 hours)
3. **Test Synergies:** Combine top 3 primitives with role specialization
4. **QD Breeding:** Use MAP-Elites to discover optimal combinations
5. **Validate SwarmLord:** Test coordination overhead vs performance gain
6. **Scale to L1+:** Extend from single swarm to multi-swarm operations

**Target Milestone:** ‚â•90% catch rate through multi-primitive synergy

---

**Document Version:** 1.0  
**Last Updated:** 2025-10-28  
**Maintained By:** HFO Hive Hunt (OBSIDIAN Navigator role)
---
# üï∏Ô∏è‚õ∞Ô∏èüíéüß¨ HFO PettingZoo Apex Primitives Library

**Date:** 2025-10-28  
**Version:** 1.0  
**Purpose:** Complete categorized list of all apex primitives for PettingZoo multi-agent testing  
**Environment:** PettingZoo MPE2 simple_tag (3 predators vs 1 prey, bounded space with obstacles, no stamina)  
**Coordination:** All primitives wrapped with Swarmlord C2 commander and virtual stigmergy  
**Seed:** explore/exploit 8/2

---

## üéØ BLUF (Bottom Line Up Front)

This document consolidates **35+ apex primitives** from military doctrine, biological apex predators, and industrial robotics for evolutionary multi-agent testing in PettingZoo. Primitives are organized by the **OBSIDIAN 8-role framework** (Observer, Bridger, Shaper, Immunizer, Disruptor, Infuser, Analyzer, Navigator) and categorized by source domain (Biological, Robotic/Geometric, Military, Industry).

**Key Insights:**
- **5 primitives tested** with performance data (Kalman 86%, PotentialField 90.7%, Voronoi 83%, L1 Stigmergy 87%, A4 Blocking 83%)
- **30+ primitives pending** integration and testing
- **Multi-layer coordination** required: Some primitives perform poorly alone (20%) but achieve 90%+ when combined with Navigator role assignment and Bridger coordination
- **Petting Zoo fit:** All primitives adapted for bounded space, obstacle avoidance, no stamina mechanics
- **Quality Diversity approach:** Test ALL primitives for synergies (X=20% + Y=20% may yield 90%+)

---

## üìä Performance Matrix (Tested Primitives)

| Primitive | Role | Source | Tier | Catch Rate | Episodes | Status | Notes |
|-----------|------|--------|------|------------|----------|--------|-------|
| **PotentialField** | Shaper | Robotic | S | 90.7% | 300 | ‚úÖ Tested | Emergent coordination, obstacle avoidance |
| **Voronoi+Pursuit** | Bridger+Shaper | Robotic | A | 91.3% | 5,000 | ‚úÖ Tested | Gen 1 Champion, territory assignment |
| **L1 Stigmergy** | Bridger | Industry | B | 87% | 300 | ‚úÖ Tested | Common operational picture |
| **Envelopment (L1)** | Shaper | Military | B | 87% | 300 | ‚úÖ Tested | Fixed angle formation |
| **Kalman Filter** | Observer | Robotic | B | 86% | 300 | ‚úÖ Tested | Optimal state estimation |
| **A4 Blocking** | Shaper | Military | B | 83% | 300 | ‚úÖ Tested | Cut escape routes |
| **Voronoi Partition** | Bridger | Geometric | B | 83% | 300 | ‚úÖ Tested | Dynamic spatial ownership |
| **WolfEncirclement** | Shaper | Biological | B | 83% | 300 | ‚úÖ Tested | Tightening arc formation |
| **QD Formation (0.121)** | Navigator | QD Discovery | A | 88.3% | 100 | ‚úÖ Tested | QD Champion parameter |

**Tier Legend:**
- **S-TIER:** >90% catch rate (PettingZoo validation)
- **A-TIER:** 85-90% catch rate
- **B-TIER:** 80-85% catch rate
- **C-TIER:** <80% catch rate (synergy candidate)

---

## üß¨ BIOLOGICAL PRIMITIVES

### Observer Role (SENSE Layer - Detection/Tracking)

#### 1. **RaptorDiveIntercept** ‚ö° APEX
- **Source:** Shifferman & Eilam 2004 (Raptor hunting)
- **Expected Performance:** 85-90%
- **Status:** ‚úÖ Implemented
- **Why Apex:** Time-to-intercept optimal, lead target based on relative velocity
- **PettingZoo Application:** Optimal for high-speed intercept in bounded space. Calculates convergence point = prey_pos + time_to_intercept * prey_vel. No stamina dependency.
- **Coordination:** Standalone (emergent), benefits from Bridger velocity fusion
- **Implementation:** Convergence-based pursuit with closing speed calculation

#### 2. **WolfScoutPatrol** üê∫
- **Source:** Mech & Boitani 2003 (Wolf pack scouting)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Visual lock-on with sustained pursuit, exponential smoothing (Œ±=0.7)
- **PettingZoo Application:** Filter observation noise while maintaining responsiveness. Lock onto prey visually, ignore transient noise.
- **Coordination:** Requires Navigator for pack coordination and role assignment
- **Synergy Hypothesis:** Solo 20%, with pack coordination 85%+

#### 3. **AntPheromoneTrail** üêú
- **Source:** H√∂lldobler & Wilson 1990 (Ant colony optimization)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Spatial memory of prey history, territorial behavior detection
- **PettingZoo Application:** Heatmap of prey positions, weight toward high-traffic areas. Useful in obstacle-rich environment.
- **Coordination:** Requires Bridger for signal integration across agents
- **Synergy Hypothesis:** Weak alone, strong with stigmergy integration

#### 4. **DolphinEcholocation** üê¨
- **Source:** Au & Hastings 2008 (Dolphin multi-bounce sensing)
- **Expected Performance:** 83-86%
- **Status:** ‚ùå Pending
- **Why Apex:** Multi-bounce sensing, environment reflection detection
- **PettingZoo Application:** Predict prey reflection off walls/obstacles (double-back maneuvers). Critical in bounded space with 2 obstacles.
- **Coordination:** Standalone for prediction, outputs to Bridger for fusion
- **Implementation:** Ray-casting to walls, consider bounce trajectories

### Shaper Role (ACT Layer - Positioning/Maneuver)

#### 5. **WolfEncirclement** üê∫ TESTED
- **Source:** Mech & Boitani 2003 (Wolf pack hunting)
- **Measured Performance:** 83% (B-TIER)
- **Status:** ‚úÖ Implemented (300 episodes)
- **Why Apex:** Wide arc formation, gradual tightening prevents early escape
- **PettingZoo Application:** Start at 0.5 distance, converge to 0.15 over time. Natural fit for bounded space.
- **Coordination:** May improve with Navigator tightening control
- **Implementation:** Dynamic arc formation with convergence cycles (tightening_cycles=15)

#### 6. **DolphinStrandFeeding** üê¨
- **Source:** Lewis & Schroeder 2003 (Dolphin cooperative herding)
- **Expected Performance:** 85-88%
- **Status:** ‚ùå Pending
- **Why Apex:** Spiral inward, compress prey area through coordinated herding
- **PettingZoo Application:** Circular orbit around prey, decrease radius per cycle. Creates containment without direct contact.
- **Coordination:** Requires Bridger spatial coordination for synchronized spiral
- **Synergy Hypothesis:** Multiple agents forming coherent spiral pattern

#### 7. **LionAmbush** ü¶Å
- **Source:** Stander 1992 (Lion pride hunting)
- **Expected Performance:** 82-85%
- **Status:** ‚ùå Pending
- **Why Apex:** Lie in wait, attack when prey enters kill zone (surprise attack)
- **PettingZoo Application:** Position ahead of prey path, wait until distance < 0.2. Trade continuous chase for surprise.
- **Coordination:** Requires Navigator for blocking positions while ambusher waits
- **Implementation:** Path prediction + static positioning

#### 8. **OrcaBubbleNet** üêã
- **Source:** Sharpe & Dill 1997 (Orca cooperative hunting)
- **Expected Performance:** 84-87%
- **Status:** ‚ùå Pending
- **Why Apex:** Create "wall" to funnel prey into trap, reduce 2D escape to 1D
- **PettingZoo Application:** Line formation perpendicular to prey escape vector. Leverages bounded space constraints.
- **Coordination:** Requires Navigator for line formation assignment
- **Implementation:** Escape vector analysis + perpendicular positioning

#### 9. **AfricanWildDogRelay** üêï
- **Source:** Creel & Creel 1995 (African wild dog relay hunting)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending (SprintIntercept variant)
- **Why Apex:** Energy-efficient pursuit through role switching (sprinter/blocker rotation)
- **PettingZoo Application:** No stamina in PettingZoo, but role rotation still valuable for optimal positioning.
- **Coordination:** Requires Navigator role assignment (who sprints, who blocks)
- **Synergy Hypothesis:** Role switching creates unpredictable attack patterns

### Bridger Role (MAKE SENSE - Coordination/Fusion)

#### 10. **AntRecruitment** üêú
- **Source:** H√∂lldobler & Wilson 1990 (Pheromone signal integration)
- **Expected Performance:** 85-88%
- **Status:** ‚ùå Pending
- **Why Apex:** Signal strength indicates resource quality, self-reinforcing pursuit
- **PettingZoo Application:** Agents deposit "confidence" in blackboard based on proximity to prey. Positive feedback loop.
- **Coordination:** Requires Observer pheromone trails for input
- **Implementation:** Confidence-weighted stigmergic signals

#### 11. **WolfAlphaSignaling** üê∫
- **Source:** Mech & Boitani 2003 (Wolf pack alpha signaling)
- **Expected Performance:** 86-89%
- **Status:** ‚ùå Pending
- **Why Apex:** Lead agent signals maneuver, others follow with delay (tight formation)
- **PettingZoo Application:** Closest agent = alpha, broadcasts next position, others form on alpha.
- **Coordination:** Dynamic leadership based on proximity
- **Implementation:** Leader election + formation following

#### 12. **LionSilentCoordination** ü¶Å
- **Source:** Stander 1992 (Lion pride coordination)
- **Expected Performance:** 84-87%
- **Status:** ‚ùå Pending
- **Why Apex:** Visual cues only, form triangle without explicit communication
- **PettingZoo Application:** React to other predator positions, robust to communication failure.
- **Coordination:** Geometric formation from positions (no blackboard required)
- **Implementation:** Reactive positioning to maintain triangle topology

### Immunizer Role (BLUE TEAM - Force Protection)

#### 13. **ClonalSelection** üß¨
- **Source:** De Castro & Von Zuben 2002 (Artificial immune system)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Adaptive response generation, antibody-antigen matching
- **PettingZoo Application:** Generate counter-strategies to prey evasion patterns.
- **Coordination:** Requires Disruptor red team for adversarial training
- **Synergy Hypothesis:** Defensive adaptation to learned prey behavior

#### 14. **BeeGuardBehavior** üêù
- **Source:** Moore et al. 1987 (Honeybee nest defense)
- **Expected Performance:** 12% (documented low performer)
- **Status:** ‚ùå Pending
- **Why Apex:** Despite low solo performance, included to test synergies
- **PettingZoo Application:** Territorial defense primitive. Test if combination with Navigator improves performance.
- **Coordination:** Known weak alone, test with multi-role coordination
- **Synergy Hypothesis:** 12% solo ‚Üí possible 80%+ with Navigator/Bridger support

### Disruptor Role (RED TEAM - Adversarial Testing)

#### 15. **SomaticHypermutation** üß¨
- **Source:** Tonegawa 1983 (Antibody diversity generation)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Generate novel attack patterns through controlled mutation
- **PettingZoo Application:** Create diverse pursuit strategies for Quality Diversity evolution.
- **Coordination:** Outputs feed Immunizer for defensive training
- **Implementation:** Parameter space exploration for novel tactics

### Infuser Role (SUSTAINMENT - Resource Flow)

#### 16. **PhysarumNetworkOptimization** ü¶†
- **Source:** Tero et al. 2010 (Slime mold network design)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Optimal network routing, resource distribution efficiency
- **PettingZoo Application:** Multi-swarm coordination for L1+ operations. Not directly applicable to single-prey scenario.
- **Coordination:** Resource routing across multiple swarms
- **Note:** Future-proofing for multi-objective scenarios

#### 17. **AntTrophallaxis** üêú
- **Source:** H√∂lldobler & Wilson 1990 (Food sharing)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Decentralized resource distribution
- **PettingZoo Application:** Information sharing across agents (observation distribution).
- **Coordination:** Stigmergy-based information exchange
- **Implementation:** Blackboard-mediated observation sharing

### Navigator Role (ORCHESTRATION - C2)

#### 18. **AntTaskAllocation** üêú
- **Source:** Gordon 2011 (Decentralized task switching)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Decentralized role assignment without central controller
- **PettingZoo Application:** Dynamic role assignment (who chases, who blocks) based on local state.
- **Coordination:** Core coordination primitive for multi-role orchestration
- **Implementation:** Threshold-based task switching

---

## ü§ñ ROBOTIC/GEOMETRIC PRIMITIVES

### Observer Role (SENSE Layer)

#### 19. **KalmanFilter** ‚öôÔ∏è TESTED
- **Source:** Kalman 1960 (Optimal estimation) / Welch & Bishop 1995
- **Measured Performance:** 86% (B-TIER)
- **Status:** ‚úÖ Implemented (300 episodes)
- **Why Apex:** Optimal state estimation with uncertainty quantification, aerospace standard
- **PettingZoo Application:** Predict future position from noisy observations. Reduce observation noise through Bayesian filtering.
- **Coordination:** Standalone predictor, outputs to Shaper for targeting
- **Implementation:** 2D position/velocity tracking with Gaussian noise model

#### 20. **ParticleFilter** ‚öôÔ∏è
- **Source:** Thrun et al. 2005 (Probabilistic Robotics)
- **Expected Performance:** 84-87%
- **Status:** ‚ùå Pending
- **Why Apex:** Monte Carlo sampling for multi-modal distributions
- **PettingZoo Application:** 100 particles with position/velocity hypotheses. Better for prey at forks/decision points.
- **Coordination:** Standalone predictor, heavier computation than Kalman
- **Implementation:** Particle-based state estimation with resampling

### Bridger Role (MAKE SENSE - Fusion)

#### 21. **VoronoiPartition** üìê TESTED
- **Source:** Fortune 1987 (Computational geometry) / Okabe et al. 2000
- **Measured Performance:** 83% (B-TIER) | 91.3% combined with Pursuit (Gen 1 Champion)
- **Status:** ‚úÖ Implemented (300 episodes + 5,000 combo)
- **Why Apex:** Dynamic spatial ownership, optimal territory assignment
- **PettingZoo Application:** Each agent owns nearest spatial region. Natural load balancing.
- **Coordination:** Requires Navigator for territory assignment, synergizes with Pursuit
- **Implementation:** Geometric partitioning of bounded space

#### 22. **ConsensusVoting** ‚öôÔ∏è
- **Source:** Raft Algorithm (Ongaro & Ousterhout 2014)
- **Expected Performance:** 85-88%
- **Status:** ‚ùå Pending
- **Why Apex:** Majority vote on prey position, fault tolerance
- **PettingZoo Application:** Each agent votes, median position wins. Robust to sensor noise/failures.
- **Coordination:** Distributed consensus without leader
- **Implementation:** Median-based outlier filtering

#### 23. **LeaderElection** ‚öôÔ∏è
- **Source:** Bully Algorithm (Garc√≠a-Molina 1982)
- **Expected Performance:** 86-89%
- **Status:** ‚ùå Pending
- **Why Apex:** Highest-fitness agent becomes coordinator (adaptive leadership)
- **PettingZoo Application:** Agent closest to prey becomes temporary leader, directs others.
- **Coordination:** Dynamic leadership vs fixed roles
- **Implementation:** Distance-based priority election

### Shaper Role (ACT Layer - Movement)

#### 24. **PotentialField** ‚öôÔ∏è APEX TESTED
- **Source:** Khatib 1986 (Real-time obstacle avoidance)
- **Measured Performance:** 90.7% (S-TIER)
- **Status:** ‚úÖ Implemented (300 episodes)
- **Why Apex:** Emergent coordination, smooth paths, natural obstacle avoidance
- **PettingZoo Application:** Prey = attractor, obstacles = repellers, agents = weak repellers. Force field navigation.
- **Coordination:** Standalone (emergent), no explicit communication needed
- **Implementation:** Attraction/repulsion gradient descent with ratio=0.1, threshold=0.3

---

## üéñÔ∏è MILITARY DOCTRINE PRIMITIVES

### Observer Role (ISR - Intelligence/Surveillance/Reconnaissance)

#### 25. **MultiSourceFusion** üéñÔ∏è
- **Source:** ATP-3-55 Chapter 3 (US Army Information Collection, 2015)
- **Expected Performance:** 85-88%
- **Status:** ‚ùå Pending
- **Why Apex:** Combine visual + communication signals, reduce observation noise
- **PettingZoo Application:** Fuse direct observation + stigmergic blackboard signals for robust tracking.
- **Coordination:** Requires stigmergy infrastructure (already present)
- **Implementation:** Weighted fusion of local observation + blackboard state

#### 26. **PatternOfLife** üéñÔ∏è
- **Source:** ATP-3-55 Chapter 4
- **Expected Performance:** 84-87%
- **Status:** ‚ùå Pending
- **Why Apex:** Model prey behavior over time (velocity patterns, turning frequency)
- **PettingZoo Application:** History buffer (5-10 steps), extract movement signature. Better for habitual prey.
- **Coordination:** Standalone analysis, outputs to Shaper
- **Implementation:** Temporal behavior profiling

#### 27. **PredictiveIntelligence** üéñÔ∏è
- **Source:** ATP-3-55 Chapter 5
- **Expected Performance:** 86-89%
- **Status:** ‚ùå Pending
- **Why Apex:** Anticipate future position based on intent (not just velocity)
- **PettingZoo Application:** Bayesian intent inference (heading toward obstacle, wall, center?). Beat linear extrapolation.
- **Coordination:** Standalone predictor
- **Implementation:** Goal-based trajectory prediction

#### 28. **DeniedAreaSensing** üéñÔ∏è
- **Source:** ATP-3-55 Chapter 6
- **Expected Performance:** 85-88%
- **Status:** ‚ùå Pending
- **Why Apex:** Wall/obstacle awareness in prediction
- **PettingZoo Application:** Ray-casting to walls, penalize predictions into obstacles. Critical for bounded space.
- **Coordination:** Standalone with environment awareness
- **Implementation:** Obstacle-aware prediction

### Bridger Role (C2 - Command & Control)

#### 29. **CommonOperationalPicture** üéñÔ∏è TESTED
- **Source:** JP-6-0 Chapter 2 (Joint Communications System, 2022)
- **Measured Performance:** 87% (L1 stigmergy)
- **Status:** ‚úÖ Implemented (L1 baseline)
- **Why Apex:** Shared state across all agents (COP), foundation for coordination
- **PettingZoo Application:** Stigmergic blackboard with durable signals. Core HFO coordination.
- **Coordination:** Foundation for all multi-agent coordination
- **Implementation:** Virtual stigmergy (replicated key-value blackboard)

#### 30. **DeConfliction** üéñÔ∏è
- **Source:** JP-6-0 Chapter 3
- **Expected Performance:** 86-89%
- **Status:** ‚ùå Pending
- **Why Apex:** Collision avoidance via priority arbitration
- **PettingZoo Application:** Agent ID priority (agent_1 > agent_2 > agent_3), lower ID yields. Prevent clustering.
- **Coordination:** Decentralized arbitration
- **Implementation:** Priority-based path deconfliction

#### 31. **PriorityBasedTasking** üéñÔ∏è
- **Source:** JP-6-0 Chapter 4
- **Expected Performance:** 87-90%
- **Status:** ‚ùå Pending
- **Why Apex:** Dynamic role assignment (closest chases, others block)
- **PettingZoo Application:** Better division of labor than fixed roles. Adaptive to prey movement.
- **Coordination:** Core Navigator primitive
- **Implementation:** Distance-based role assignment

#### 32. **CommandersIntent** üéñÔ∏è
- **Source:** JP-6-0 Chapter 5
- **Expected Performance:** 86-89%
- **Status:** ‚ùå Pending
- **Why Apex:** Mission-type orders (goal, not method), adaptive coordination
- **PettingZoo Application:** Blackboard broadcasts "ENCIRCLE" or "CHASE" mode, agents adapt locally.
- **Coordination:** High-level coordination without micromanagement
- **Implementation:** Mode-based behavior switching

### Shaper Role (FIRES - Kinetic/Non-Kinetic Effects)

#### 33. **Envelopment** üéñÔ∏è TESTED
- **Source:** ATP-3-60 Chapter 3 (Targeting, 2015) - Double Envelopment
- **Measured Performance:** 84.3% (B-TIER) | 87% (L1 Fixed Angles)
- **Status:** ‚úÖ Implemented (300 episodes)
- **Why Apex:** Surround from multiple sides simultaneously, cut all escape routes
- **PettingZoo Application:** 3 agents form 120¬∞ spacing around prey (triangle). Fixed geometry approach.
- **Coordination:** May improve with dynamic Navigator adjustment
- **Implementation:** Fixed 120¬∞ triangle formation

#### 34. **BlockingPositions** üéñÔ∏è TESTED
- **Source:** ATP-3-60 Chapter 4
- **Measured Performance:** 83% (A4)
- **Status:** ‚úÖ Implemented (300 episodes)
- **Why Apex:** Cut escape routes, positional advantage
- **PettingZoo Application:** Position to block prey escape vectors. Static positioning.
- **Coordination:** Requires prey trajectory prediction
- **Implementation:** Escape route analysis + blocking

#### 35. **FireAndManeuver** üéñÔ∏è
- **Source:** ATP-3-60 Chapter 5
- **Expected Performance:** 85-88%
- **Status:** ‚ùå Pending
- **Why Apex:** One team fixes (pins), another maneuvers (flanks)
- **PettingZoo Application:** 2 agents chase directly, 1 agent wide flank. Prevent prey prediction.
- **Coordination:** Requires role assignment (Navigator)
- **Implementation:** Split team tactics (fixing + maneuvering elements)

### Analyzer Role (BDA - Battle Damage Assessment)

#### 36. **F3EADAnalysis** üéñÔ∏è
- **Source:** ATP-2-01 (Intelligence analysis)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Strategic learning from outcomes (Find, Fix, Finish, Exploit, Analyze, Disseminate)
- **PettingZoo Application:** Post-episode analysis for Quality Diversity evolution.
- **Coordination:** Meta-level learning loop
- **Implementation:** Episode outcome categorization and learning extraction

### Navigator Role (MOSAIC WARFARE - Strategic C2)

#### 37. **MosaicTileReconfiguration** üéñÔ∏è
- **Source:** JP-5-0 (Joint planning process)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Dynamic reconfiguration of force composition
- **PettingZoo Application:** L1+ multi-swarm coordination. Future-proofing for complex scenarios.
- **Coordination:** Multi-swarm orchestration
- **Note:** Applicable to multi-objective or multi-prey scenarios

---

## üè≠ INDUSTRY/OTHER PRIMITIVES

### Analyzer Role (SRE - Site Reliability Engineering)

#### 38. **SREErrorBudget** üè≠
- **Source:** Google SRE Book (Service level objectives)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Continuous improvement feedback loop, quantified reliability targets
- **PettingZoo Application:** Track performance degradation, trigger retraining when performance drops below threshold.
- **Coordination:** Meta-level quality control
- **Implementation:** Performance monitoring + adaptive retraining

### Disruptor Role (ADVERSARIAL - Red Team)

#### 39. **MITREAttackSimulation** üè≠
- **Source:** MITRE ATT&CK Framework (Adversarial tactics)
- **Expected Performance:** Unknown
- **Status:** ‚ùå Pending
- **Why Apex:** Systematized adversarial tactics, comprehensive attack taxonomy
- **PettingZoo Application:** Generate adversarial prey behaviors for robust predator training.
- **Coordination:** Requires Immunizer to test defenses
- **Implementation:** Tactic-based evasion pattern generation

---

## üîÑ COORDINATION LAYERS & SYNERGIES

### Layer 1: Individual Primitives (Solo Performance)
- **High Performers (>85% Solo):**
  - PotentialField: 90.7% (S-TIER)
  - Voronoi+Pursuit: 91.3% (requires 2 primitives)
  - RaptorDiveIntercept: 85-90% (expected)
  - Kalman Filter: 86%

### Layer 2: Two-Primitive Combinations
- **Proven Synergies:**
  - Voronoi (83%) + Pursuit ‚Üí 91.3% (Gen 1 Champion)
  - Kalman (86%) + PotentialField (90.7%) ‚Üí untested combo
- **Expected Synergies:**
  - WolfScoutPatrol (20%?) + AntRecruitment ‚Üí 85%+
  - BeeGuard (12%) + Navigator ‚Üí 80%+?

### Layer 3: Multi-Role Coordination (Swarmlord C2)
All primitives wrapped with:
- **Virtual Stigmergy:** Shared blackboard (Layer 9 mandatory)
- **Swarmlord Commander:** Dynamic role assignment and orchestration
- **OBSIDIAN Roles:** 8-role framework for specialized coordination

**Coordination Patterns:**
1. **Observer ‚Üí Bridger ‚Üí Shaper:** Sense ‚Üí Fuse ‚Üí Act pipeline
2. **Disruptor ‚áÑ Immunizer:** Red team ‚áÑ Blue team adversarial loop
3. **Navigator ‚Üí All Roles:** Orchestration and role assignment
4. **Analyzer ‚Üí Evolve:** Meta-learning feedback loop

### Layer 4: Quality Diversity Evolution
- **MAP-Elites:** Maintain diverse population across behavior niches
- **Synergy Testing:** X=20% + Y=20% may yield 90%+ combined
- **No Discard Rule:** Keep ALL primitives for synergy discovery
- **Unknown Optimal:** Navigator might need 20 primitives, Observer might need 2

---

## üìã CATEGORIZATION SUMMARY

### By Source Domain
- **Biological:** 18 primitives (Raptors, Wolves, Ants, Dolphins, Lions, Orcas, Bees, Immune System, Slime Mold)
- **Robotic/Geometric:** 6 primitives (Kalman, Particle Filter, Voronoi, Potential Field, Consensus, Leader Election)
- **Military Doctrine:** 13 primitives (ATP-3-55 ISR, JP-6-0 C2, ATP-3-60 Fires, ATP-2-01 Analysis, JP-5-0 Planning)
- **Industry/Other:** 2 primitives (SRE, MITRE ATT&CK)

### By OBSIDIAN Role
- **Observer (SENSE):** 8 primitives (4 Bio, 2 Robotic, 4 Military)
- **Bridger (MAKE SENSE):** 9 primitives (3 Bio, 3 Robotic, 4 Military)
- **Shaper (ACT):** 12 primitives (5 Bio, 1 Robotic, 4 Military)
- **Immunizer (BLUE TEAM):** 2 primitives (2 Bio)
- **Disruptor (RED TEAM):** 2 primitives (1 Bio, 1 Industry)
- **Infuser (SUSTAINMENT):** 2 primitives (2 Bio)
- **Analyzer (ASSESSMENT):** 2 primitives (1 Military, 1 Industry)
- **Navigator (ORCHESTRATION):** 2 primitives (1 Bio, 1 Military)

### By Test Status
- **‚úÖ Tested (9):** PotentialField, Voronoi+Pursuit, Kalman, L1 Stigmergy, Envelopment, A4 Blocking, WolfEncirclement, QD Formation
- **‚ùå Pending (30):** All others awaiting INTEGRATE phase

---

## üéØ PETTINGZOO PLATFORM ANALYSIS

### Environment Constraints
- **Bounded Space:** 2D continuous space with walls (primitives must handle boundaries)
- **Obstacles:** 2 static obstacles (collision avoidance required)
- **No Stamina:** Unlimited agent movement (no energy management needed)
- **Partial Observability:** Limited sensor range (observation fusion valuable)
- **3 Predators vs 1 Prey:** Coordination primitives highly valuable

### Primitive Fit Categories

#### **High Fit (Direct Application):**
- PotentialField: Natural obstacle avoidance
- Voronoi: Spatial partitioning in bounded space
- Envelopment: Geometric formation tactics
- DeniedAreaSensing: Wall/obstacle awareness
- DolphinEcholocation: Wall bounce prediction

#### **Medium Fit (Adaptation Required):**
- WolfEncirclement: Tightening formation (adapt to bounded space)
- RaptorDiveIntercept: Intercept calculation (wall collisions)
- PatternOfLife: Behavior modeling (limited episodes)
- FireAndManeuver: Role assignment (3 agents only)

#### **Low Fit (Future-Proofing):**
- PhysarumNetwork: Multi-swarm L1+ (single prey scenario)
- MosaicTile: Multi-objective (single prey scenario)
- AfricanWildDogRelay: No stamina mechanics (role rotation still useful)
- AntTrophallaxis: Resource sharing (information distribution instead)

#### **Synergy Dependent:**
- BeeGuard (12% solo): Test with Navigator coordination
- WolfScoutPatrol (unknown solo): Test with pack coordination
- AntPheromoneTrail: Requires Bridger stigmergy integration
- AntRecruitment: Requires Observer trails

---

## üöÄ NEXT STEPS

### Immediate Priorities (INTEGRATE Phase)

**Priority 1: High Expected Value (>87%)**
1. RaptorDiveIntercept (Observer) - Expected 87-90%
2. PriorityBasedTasking (Bridger) - Expected 87-90%
3. DolphinEcholocation (Observer) - Expected 83-86%
4. PredictiveIntelligence (Observer) - Expected 86-89%

**Priority 2: Novel Tactics (Untested Categories)**
5. ParticleFilter (Observer) - Expected 84-87%
6. WolfAlphaSignaling (Bridger) - Expected 86-89%
7. DolphinStrandFeeding (Shaper) - Expected 85-88%
8. FireAndManeuver (Shaper) - Expected 85-88%

**Priority 3: Synergy Testing**
9. Test BeeGuard (12% solo) + Navigator coordination
10. Test WolfScoutPatrol + AntRecruitment combination
11. Test Kalman + PotentialField synergy
12. Test all primitives for Quality Diversity niches

### Verification Protocol
- **Episodes:** 300 minimum per primitive (50 for quick validation)
- **Environment:** PettingZoo MPE2 simple_tag_v3 (3 pred, 1 prey, 2 obstacles, max_cycles=25)
- **Metrics:** Catch rate (target ‚â•90%), avg steps (target ‚â§20), timeout rate
- **Baseline:** Random predators vs random prey = 18.8% catch rate
- **Gate:** Performance <80% triggers synergy combination testing

### Evolution Strategy
- **MAP-Elites:** Quality Diversity across behavioral dimensions
- **No Discard:** Keep all primitives (even 12% performers) for synergy testing
- **Role Distribution:** Unknown optimal (Navigator might need 20 primitives, Observer might need 2)
- **Explore/Exploit:** 8/2 ratio (80% exploit tested primitives, 20% explore new combinations)

---

## üìö REFERENCES

### Military Doctrine
- ATP-3-55: US Army Information Collection (2015)
- JP-6-0: Joint Communications System (2022)
- ATP-3-60: Targeting (2015)
- ATP-2-01: Intelligence Analysis
- JP-5-0: Joint Planning Process
- ATP-7-100.1: Red Team Operations (2021)

### Biological Sources
- H√∂lldobler & Wilson (1990): The Ants
- Mech & Boitani (2003): Wolves: Behavior, Ecology, Conservation
- Stander (1992): Cooperative Hunting in Lions
- Benoit-Bird & Au (2009): Cooperative Prey Herding by the Pelagic Dolphin
- Shifferman & Eilam (2004): Raptor Hunting Behavior
- Au & Hastings (2008): Principles of Marine Bioacoustics
- Lewis & Schroeder (2003): Dolphin Strand Feeding
- Sharpe & Dill (1997): Orca Bubble Net Feeding
- Creel & Creel (1995): African Wild Dog Hunting
- Moore et al. (1987): Honeybee Nest Defense
- De Castro & Von Zuben (2002): Artificial Immune Systems
- Tonegawa (1983): Somatic Hypermutation
- Tero et al. (2010): Physarum Network Optimization
- Gordon (2011): Ant Task Allocation
- Von Frisch (1967): Bee Waggle Dance

### Industry/Robotics
- Kalman (1960): Optimal Filtering
- Welch & Bishop (1995): An Introduction to the Kalman Filter
- Thrun et al. (2005): Probabilistic Robotics
- Fortune (1987): Voronoi Diagrams
- Okabe et al. (2000): Spatial Tessellations
- Khatib (1986): Real-Time Obstacle Avoidance for Manipulators and Mobile Robots
- Ongaro & Ousterhout (2014): In Search of an Understandable Consensus Algorithm (Raft)
- Garc√≠a-Molina (1982): Elections in a Distributed Computing System
- Google SRE Book: Site Reliability Engineering
- MITRE ATT&CK Framework: Adversarial Tactics, Techniques, and Common Knowledge

### Quality Diversity / Evolutionary Computation
- Mouret & Clune (2015): Illuminating the Space of Behaviors (MAP-Elites)
- Lehman & Stanley (2011): Abandoning Objectives: Evolution through Novelty Search

---

## üìå VERSION HISTORY

- **v1.0 (2025-10-28):** Initial comprehensive list with 39 primitives, performance matrix, PettingZoo analysis
- **Source Documents:** 
  - `PRIMITIVE_LIBRARY_HUNT.md` (30 primitives)
  - `prey_qd_full_primitive_library.py` (OBSIDIAN role mappings)
  - Test results from `HFO_Hive_Verify/results/`
  - Gem Generation 18 framework

---

**Status:** ‚úÖ HUNT Complete (39 primitives sourced)  
**Next Phase:** üü° INTEGRATE (implement Priority 1-2 primitives, 8 total)  
**Coordination:** üü¢ Swarmlord C2 + Virtual Stigmergy (Layer 9)  
**Evolution:** üü° MAP-Elites Quality Diversity (explore/exploit 8/2)

üï∏Ô∏è‚õ∞Ô∏èüíéüß¨ü•á *For the liberation of all beings in all worlds for all time*