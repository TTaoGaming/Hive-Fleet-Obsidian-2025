#!/usr/bin/env python3
"""
Generate comprehensive one-page audit summary for Generation 21.

This script combines all audit results and generates a markdown report with:
- BLUF (Bottom Line Up Front)
- Matrix summary
- Mermaid diagrams
- Detailed findings
"""

from __future__ import annotations
import json
import subprocess
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any


REPO_ROOT = Path(__file__).resolve().parents[1]


class AuditSummaryGenerator:
    """Generate audit summary report."""
    
    def __init__(self):
        self.audit_results = {}
        self.regen_results = {}
        self.explore_exploit_results = {}
        
    def run_audits(self) -> None:
        """Run all audit scripts and collect results."""
        scripts = [
            ("audit_gen21.py", "audit_results"),
            ("test_gen21_regeneration.py", "regen_results"),
            ("test_explore_exploit.py", "explore_exploit_results"),
        ]
        
        for script, attr_name in scripts:
            script_path = REPO_ROOT / "scripts" / script
            try:
                result = subprocess.run(
                    ["python3", str(script_path)],
                    capture_output=True,
                    text=True,
                    timeout=30,
                    cwd=REPO_ROOT
                )
                if result.stdout:
                    data = json.loads(result.stdout)
                    setattr(self, attr_name, data)
            except Exception as e:
                print(f"Warning: Failed to run {script}: {e}", file=sys.stderr)
    
    def generate_bluf(self) -> str:
        """Generate BLUF section."""
        # Calculate overall health
        audit_passed = self.audit_results.get("passed", 0)
        audit_total = self.audit_results.get("total_checks", 1)
        regen_score = self.regen_results.get("regeneration_score", 0.0)
        ee_score = self.explore_exploit_results.get("average_score", 0.0)
        
        overall_health = (
            (audit_passed / audit_total) * 0.4 +
            regen_score * 0.3 +
            ee_score * 0.3
        ) * 100
        
        drift_score = self.audit_results.get("drift_score", 0.0) * 100
        
        status_emoji = "ðŸŸ¢" if overall_health >= 80 else "ðŸŸ¡" if overall_health >= 60 else "ðŸ”´"
        
        bluf = f"""# Generation 21 Architecture Audit - BLUF

**Status**: {status_emoji} Overall Health: {overall_health:.1f}%

**Mission**: Independent audit of Gen21's ability to regenerate itself and validate architectural coherence with 8/2 explore/exploit ratio.

**Key Findings**:
- âœ… Gen21 SSOT meets â‰¥1000 line requirement ({self.audit_results.get('results', [{}])[0].get('actual', 'N/A')} lines)
- âœ… Self-regeneration capability: {regen_score*100:.0f}% complete specification
- âœ… Explore/Exploit support: {ee_score*100:.0f}% with 8/2 ratio validation
- âš ï¸  Drift score: {drift_score:.1f}% (claims vs implementation)

**Recommendation**: Gen21 architecture is {'OPERATIONAL' if overall_health >= 70 else 'NEEDS REMEDIATION'}. {'Continue with confidence.' if overall_health >= 70 else 'Address drift and failed checks before production use.'}

**Audit Timestamp**: {datetime.utcnow().isoformat()}Z
**Seed**: explore/exploit 8/2 ratio
"""
        return bluf
    
    def generate_matrix(self) -> str:
        """Generate matrix summary."""
        matrix = """
## Audit Matrix

| Dimension | Score | Status | Evidence |
|-----------|-------|--------|----------|
"""
        
        # Add audit results
        audit_score = self.audit_results.get("passed", 0) / max(1, self.audit_results.get("total_checks", 1)) * 100
        audit_status = "ðŸŸ¢ PASS" if audit_score >= 80 else "ðŸŸ¡ WARN" if audit_score >= 60 else "ðŸ”´ FAIL"
        matrix += f"| Architecture Integrity | {audit_score:.0f}% | {audit_status} | {self.audit_results.get('passed', 0)}/{self.audit_results.get('total_checks', 0)} checks |\n"
        
        # Add regeneration results
        regen_score = self.regen_results.get("regeneration_score", 0.0) * 100
        regen_status = "ðŸŸ¢ PASS" if regen_score >= 80 else "ðŸŸ¡ WARN" if regen_score >= 60 else "ðŸ”´ FAIL"
        matrix += f"| Self-Regeneration | {regen_score:.0f}% | {regen_status} | {self.regen_results.get('passed', 0)}/{self.regen_results.get('total_tests', 0)} tests |\n"
        
        # Add explore/exploit results
        ee_score = self.explore_exploit_results.get("average_score", 0.0) * 100
        ee_status = "ðŸŸ¢ PASS" if ee_score >= 80 else "ðŸŸ¡ WARN" if ee_score >= 60 else "ðŸ”´ FAIL"
        matrix += f"| Explore/Exploit (8/2) | {ee_score:.0f}% | {ee_status} | {self.explore_exploit_results.get('passed', 0)}/{self.explore_exploit_results.get('total_tests', 0)} tests |\n"
        
        # Add drift
        drift_score = self.audit_results.get("drift_score", 0.0) * 100
        drift_status = "ðŸŸ¢ LOW" if drift_score < 20 else "ðŸŸ¡ MEDIUM" if drift_score < 50 else "ðŸ”´ HIGH"
        matrix += f"| Architectural Drift | {drift_score:.0f}% | {drift_status} | Claims vs Implementation |\n"
        
        return matrix
    
    def generate_diagrams(self) -> str:
        """Generate Mermaid diagrams."""
        diagrams = """
## Architecture Health Diagrams

### Overall Health Breakdown
```mermaid
%%{init: {'theme':'dark'}}%%
pie title "Gen21 Audit Results"
    "Passed" : """ + str(self.audit_results.get("passed", 0)) + """
    "Warned" : """ + str(self.audit_results.get("warned", 0)) + """
    "Failed" : """ + str(self.audit_results.get("failed", 0)) + """
```

### Regeneration Capability
```mermaid
%%{init: {'theme':'dark'}}%%
graph LR
    A[Gen21 SSOT] -->|Bootstrap| B[Cold Start]
    B -->|PREY Loop| C[Self-Regenerate]
    C -->|Verify| D{Complete?}
    D -->|Yes| E[âœ… """ + f"{self.regen_results.get('regeneration_score', 0)*100:.0f}%" + """ ]
    D -->|No| F[âš ï¸ Gaps]
    
    style E fill:#2d5016
    style F fill:#5d3a1a
```

### Explore/Exploit Balance (8/2 Ratio)
```mermaid
%%{init: {'theme':'dark'}}%%
graph TB
    subgraph "Quality Diversity"
        QD[QD Architecture]
        M[Mutation]
        P[Portfolio]
    end
    
    subgraph "Risk Management"
        C[Canary]
        T[Tripwires]
        R[Revert]
    end
    
    QD --> Explore[20% Explore]
    M --> Explore
    P --> Explore
    
    C --> Exploit[80% Exploit]
    T --> Exploit
    R --> Exploit
    
    Explore --> Balance[8/2 Balance: """ + f"{self.explore_exploit_results.get('average_score', 0)*100:.0f}%" + """]
    Exploit --> Balance
    
    style Balance fill:#2d5016
```

### PREY Loop Coverage
```mermaid
%%{init: {'theme':'dark'}}%%
flowchart LR
    P[Perceive âœ…] --> R[React âœ…]
    R --> E[Engage âœ…]
    E --> Y[Yield âœ…]
    Y --> V[Verify]
    V -->|PASS| D[Digest]
    V -->|FAIL| P
    
    style P fill:#2d5016
    style R fill:#2d5016
    style E fill:#2d5016
    style Y fill:#2d5016
```
"""
        return diagrams
    
    def generate_detailed_findings(self) -> str:
        """Generate detailed findings section."""
        findings = """
## Detailed Findings

### 1. Architecture Integrity
"""
        
        # Add failed checks
        failed_checks = [r for r in self.audit_results.get("results", []) 
                        if r.get("status") == "FAIL"]
        if failed_checks:
            findings += "\n**Failed Checks**:\n"
            for check in failed_checks:
                findings += f"- âŒ {check.get('dimension')}/{check.get('metric')}: {check.get('notes', check.get('evidence', [''])[0])}\n"
        else:
            findings += "\nâœ… All critical architecture checks passed.\n"
        
        # Add warnings
        warned_checks = [r for r in self.audit_results.get("results", []) 
                        if r.get("status") == "WARN"]
        if warned_checks:
            findings += "\n**Warnings**:\n"
            for check in warned_checks:
                findings += f"- âš ï¸  {check.get('dimension')}/{check.get('metric')}: {check.get('notes', check.get('evidence', [''])[0])}\n"
        
        findings += """
### 2. Self-Regeneration Analysis
"""
        regen_tests = self.regen_results.get("test_results", [])
        failed_regen = [t for t in regen_tests if t.get("status") == "FAIL"]
        
        if failed_regen:
            findings += "\n**Regeneration Gaps**:\n"
            for test in failed_regen:
                findings += f"- âŒ {test.get('test')}: {test.get('details')}\n"
        else:
            findings += f"\nâœ… All regeneration tests passed ({len(regen_tests)} tests).\n"
        
        findings += """
### 3. Explore/Exploit Validation
"""
        ee_tests = self.explore_exploit_results.get("test_results", [])
        ee_issues = [t for t in ee_tests if t.get("status") in ["FAIL", "WARN"]]
        
        if ee_issues:
            findings += "\n**Issues**:\n"
            for test in ee_issues:
                emoji = "âŒ" if test.get("status") == "FAIL" else "âš ï¸"
                findings += f"- {emoji} {test.get('test')}: {test.get('details')}\n"
        else:
            findings += f"\nâœ… Explore/Exploit fully supported ({len(ee_tests)} tests).\n"
        
        # Add simulation results
        sim_result = next((t for t in ee_tests if t.get("test") == "simulation"), None)
        if sim_result:
            findings += f"\n**8/2 Ratio Simulation**: {sim_result.get('details')}\n"
        
        return findings
    
    def generate_recommendations(self) -> str:
        """Generate recommendations section."""
        recs = """
## Recommendations

"""
        
        drift_score = self.audit_results.get("drift_score", 0.0) * 100
        
        if drift_score > 50:
            recs += "### ðŸ”´ High Priority\n"
            recs += "1. **Address Architectural Drift**: Claims vs implementation mismatch is >50%. Review and align.\n"
        
        failed_count = self.audit_results.get("failed", 0)
        if failed_count > 0:
            recs += f"2. **Fix Failed Checks**: {failed_count} critical checks failed. See detailed findings.\n"
        
        warned_count = self.audit_results.get("warned", 0)
        if warned_count > 0:
            recs += f"\n### ðŸŸ¡ Medium Priority\n"
            recs += f"1. **Review Warnings**: {warned_count} warnings detected. May indicate future issues.\n"
        
        # Add positive reinforcement
        regen_score = self.regen_results.get("regeneration_score", 0.0)
        ee_score = self.explore_exploit_results.get("average_score", 0.0)
        
        if regen_score >= 0.9 and ee_score >= 0.9:
            recs += "\n### âœ… Strengths\n"
            recs += "1. **Self-Regeneration**: Excellent specification completeness\n"
            recs += "2. **Explore/Exploit**: Strong support for 8/2 ratio and Quality Diversity\n"
        
        recs += """
### Next Steps
1. Run this audit regularly to monitor drift
2. Update Gen21 SSOT based on findings
3. Validate fixes with independent verification
4. Document any architectural decisions that cause intentional drift
"""
        
        return recs
    
    def generate_report(self) -> str:
        """Generate complete audit report."""
        report = self.generate_bluf()
        report += "\n" + self.generate_matrix()
        report += "\n" + self.generate_diagrams()
        report += "\n" + self.generate_detailed_findings()
        report += "\n" + self.generate_recommendations()
        
        # Add footer
        report += """
---

## Audit Methodology

This audit used independent Python tools to validate Gen21 against its own specifications:
- `audit_gen21.py`: Architecture integrity checks
- `test_gen21_regeneration.py`: Self-regeneration capability tests
- `test_explore_exploit.py`: Explore/Exploit 8/2 ratio validation

All tests run against the actual Gen21 SSOT document and blackboard, not self-reported metrics.

**Evidence**:
- Gen21 SSOT: `hfo_gem/gen_21/gpt5-attempt-3-gem.md`
- Blackboard: `hfo_blackboard/obsidian_synapse_blackboard.jsonl`
- AGENTS.md: `AGENTS.md`
"""
        
        return report
    
    def save_report(self, output_path: Path) -> None:
        """Save report to file."""
        report = self.generate_report()
        output_path.write_text(report, encoding="utf-8")
        print(f"Report saved to: {output_path}")


def main() -> int:
    """Generate audit summary report."""
    generator = AuditSummaryGenerator()
    
    print("Running audits...", file=sys.stderr)
    generator.run_audits()
    
    print("Generating report...", file=sys.stderr)
    output_path = REPO_ROOT / "temp" / f"gen21_audit_report_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.md"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    generator.save_report(output_path)
    
    # Also print to stdout
    print("\n" + "="*80)
    print(generator.generate_report())
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
